{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07646510-d879-4481-96b8-c50baaffb2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_rank_clean = df_rank.reset_index(drop=True).copy()\n",
    "missing_idx = np.where(df_rank_clean['score'].isna())[0]\n",
    "n = len(df_rank_clean)\n",
    "\n",
    "for i in missing_idx:\n",
    "    left  = df_rank_clean['score'].iloc[i-1] if i-1 >= 0 else np.nan\n",
    "    right = df_rank_clean['score'].iloc[i+1] if i+1 < n   else np.nan\n",
    "    df_rank_clean.at[i, 'score'] = np.nanmean([left, right])\n",
    "\n",
    "# In case both neighbors were NaN:\n",
    "df_rank_clean['score'] = df_rank_clean['score'].interpolate(limit_direction='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d926cef6-8c0d-4127-844c-a6ad7afc6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.groupby([\"year\", \"country\"]).size().reset_index(name=\"university_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c6207b-42c5-41c6-807f-b3a7e459012b",
   "metadata": {},
   "source": [
    "### Moving Average Forecasting\n",
    "To smooth out short-term fluctuations and highlight longer-term trends or cycles.\n",
    "\n",
    "Concept:\n",
    "Uses the average of past $k$ observations to predict the next value.\n",
    "\n",
    "Simple Moving Average of window size $k$ \n",
    "\n",
    "$$\\hat{y}_t = \\frac{1}{k} \\sum_{i = t - k}^{t - 1} y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8070fb82-c130-46eb-b27a-9187eb6a6eac",
   "metadata": {},
   "source": [
    "### Exponential Smoothing (Single & Holt-Winters)\n",
    "To give more weight to recent data points, which often better reflect future trends. Holt-Winters also captures trend and seasonality.\n",
    "\n",
    "Concept:\n",
    "A weighted average where weights decline exponentially for older observations.\n",
    "\n",
    "**Single Exponential Smoothing**:\n",
    "$$\\hat{y}_t = \\alpha y_{t-1} + (1 - \\alpha) \\hat{y}_{t-1}$$\n",
    "\n",
    "Where $\\alpha \\in [0, 1]$ is the smoothing parameter.\n",
    "\n",
    "**Holtâ€™s Linear Trend Method (Two Parameters)**:\n",
    "$$\\begin{align*}\n",
    "\\ell_t &= \\alpha y_t + (1 - \\alpha)(\\ell_{t-1} + b_{t-1}) \\\\\n",
    "b_t &= \\beta (\\ell_t - \\ell_{t-1}) + (1 - \\beta) b_{t-1} \\\\\n",
    "\\hat{y}_{t+h} &= \\ell_t + h b_t\n",
    "\\end{align*}$$\n",
    "\n",
    "**Holt-Winters (Additive Seasonal):**\n",
    "$$\\hat{y}_{t+h} = \\ell_t + h b_t + s_{t - m + (h \\bmod m)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68a50c-0dd4-4a12-b62a-80c3be3cdf75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bed7a624-cd57-42b3-8817-edf10e5749f5",
   "metadata": {},
   "source": [
    "### ARIMAX (ARIMA with Exogenous Variables)\n",
    "o include external influences (GDP) in the ARIMA model.\n",
    "\n",
    "**Concept**\n",
    "Adds exogenous (independent) variables to ARIMA, enabling better prediction if those variables explain the variance.\n",
    "\n",
    "ARIMAX Equation\n",
    "\n",
    "$$\n",
    "y_t = \\beta_0 + \\sum_{i=1}^{p} \\phi_i y_{t-i} + \\sum_{j=1}^{q} \\theta_j \\varepsilon_{t-j} + \\sum_{k=1}^{m} \\gamma_k x_{k,t} + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$\\quad x_{k,t}$: exogenous variables (e.g., GDP)  \n",
    "$\\quad \\gamma_k$: coefficients for exogenous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b43ed0-eddf-455d-b989-6f537c7fc59b",
   "metadata": {},
   "source": [
    "### ARIMA (Autoregressive Integrated Moving Average)\n",
    "A powerful time-series model that combines autoregression, differencing (to remove trends), and moving averages.\n",
    "\n",
    "**Concept**\n",
    "ARIMA(p,d,q) models the data as:\n",
    "\n",
    "AR (p): regression on past values\n",
    "\n",
    "I (d): differencing to remove trend\n",
    "\n",
    "MA (q): regression on past forecast errors\n",
    "\n",
    "**General ARIMA Equation**\n",
    "$$\n",
    "\\phi(B)(1 - B)^d y_t = \\theta(B) \\varepsilon_t\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "-$\\quad \\phi(B)$: autoregressive (AR) polynomial  \n",
    "-$\\quad \\theta(B)$: moving average (MA) polynomial  \n",
    "-$\\quad B$: backshift operator, $B y_t = y_{t-1}$  \n",
    "-$\\quad \\varepsilon_t$: white noise (error term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3c6c3-1408-4bc3-a5a7-915aeb694e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count universities per country per year\n",
    "counts_per_year = (\n",
    "    df_clean.groupby([\"year\", \"country\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"university_count\")\n",
    ")\n",
    "\n",
    "# Get top 10 countries for each year\n",
    "top10_by_universities = (\n",
    "    counts_per_year.groupby(\"year\", group_keys=False)\n",
    "    .apply(lambda x: x.sort_values(\"university_count\", ascending=False).head(10))\n",
    ")\n",
    "top10_by_universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96091d-2b75-417c-a8d7-3efde3e55723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sort original data by year, country, and score descending\n",
    "df_sorted = df_clean.sort_values(by=[\"year\", \"country\", \"score\"], ascending=[True, True, False])\n",
    "\n",
    "# Step 2: Get top 5 universities per country per year\n",
    "df_top5 = df_sorted.groupby([\"year\", \"country\"]).head(10)\n",
    "\n",
    "# Step 3: Compute average score from top 5\n",
    "avg_top5_scores = df_top5.groupby([\"year\", \"country\"], as_index=False)[\"score\"].mean()\n",
    "\n",
    "# Step 4: Get top 10 countries per year\n",
    "top10_by_year = (\n",
    "    avg_top5_scores.groupby(\"year\", group_keys=False)\n",
    "    .apply(lambda x: x.sort_values(\"score\", ascending=False).head(10))\n",
    "    .reset_index(drop=True)    \n",
    ")\n",
    "# Display results\n",
    "for year in sorted(top10_by_year[\"year\"].unique()):\n",
    "    print(f\"\\nðŸ“… Top 10 Countries in {year}:\")\n",
    "    display(top10_by_year[top10_by_year[\"year\"] == year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc5280-10bd-4e86-b44f-555b9843140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Prepare data (we use the same top countries DataFrame)\n",
    "X = filtered_df[[\"gdp_per_capita\"]]\n",
    "y = filtered_df[\"score\"]\n",
    "\n",
    "# Step 2: Initialize and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Step 3: Get coefficients\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "r_squared = model.score(X, y)\n",
    "\n",
    "print(f\"ðŸ“ˆ Linear Regression Model:\")\n",
    "print(f\"score = {slope:.4f} * gdp_per_capita + {intercept:.2f}\")\n",
    "print(f\"RÂ² (explained variance): {r_squared:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c86838-d44b-4b0f-baba-c48f2395b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot + regression line\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=\"gdp_per_capita\", y=\"score\", data=filtered_df, label=\"Data\")\n",
    "plt.plot(X, model.predict(X), color=\"red\", label=\"Regression Line\")\n",
    "\n",
    "plt.title(\"GDP per Capita vs. University Score (Top Countries)\")\n",
    "plt.xlabel(\"GDP per Capita (USD)\")\n",
    "plt.ylabel(\"Average University Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f05d2-0502-4a95-b30e-b35b32f0936b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c4eb51-8bcb-4450-abea-418c5dae2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Define new feature list\n",
    "log_features = [\n",
    "    \"log_gdp_per_capita\",\n",
    "    \"gov_exp_pct_gdp\",\n",
    "    \"lit_rate_adult_pct\",\n",
    "    \"school_enrol_primary_pct\",\n",
    "    \"school_enrol_secondary_pct\",\n",
    "    \"school_enrol_tertiary_pct\"\n",
    "]\n",
    "\n",
    "# Drop missing\n",
    "log_model_data = merged_df.dropna(subset=log_features + [\"score\"])\n",
    "X_log = log_model_data[log_features]\n",
    "y_log = log_model_data[\"score\"]\n",
    "\n",
    "# Fit the model\n",
    "log_model = LinearRegression()\n",
    "log_model.fit(X_log, y_log)\n",
    "y_log_pred = log_model.predict(X_log)\n",
    "\n",
    "# Print results\n",
    "print(\"ðŸ“Š Multiple Regression with log(GDP):\")\n",
    "for f, coef in zip(log_features, log_model.coef_):\n",
    "    print(f\"{f}: {coef:.4f}\")\n",
    "\n",
    "print(f\"\\nIntercept: {log_model.intercept_:.2f}\")\n",
    "print(f\"RÂ² (explained variance): {r2_score(y_log, y_log_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138cc06e-12fd-49d1-b050-d28d090c6777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aa98cd-1523-472a-9b04-a7e6f3c95dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define the features used in your log-GDP regression model\n",
    "features = [\n",
    "    \"log_gdp_per_capita\",\n",
    "    \"gov_exp_pct_gdp\",\n",
    "    \"lit_rate_adult_pct\",\n",
    "    \"school_enrol_primary_pct\",\n",
    "    \"school_enrol_secondary_pct\",\n",
    "    \"school_enrol_tertiary_pct\"\n",
    "]\n",
    "\n",
    "# Step 2: Create a minimal input row for 2024\n",
    "# Replace these values with averages or reasonable estimates\n",
    "input_row_2024 = pd.DataFrame([{\n",
    "    \"log_gdp_per_capita\": np.log(forecasted_gdp),\n",
    "    \"gov_exp_pct_gdp\": 5.0,                  # average: ~5% of GDP\n",
    "    \"lit_rate_adult_pct\": 99.0,              # high literacy for US\n",
    "    \"school_enrol_primary_pct\": 102.0,       # slightly over 100% (common due to repeaters)\n",
    "    \"school_enrol_secondary_pct\": 95.0,\n",
    "    \"school_enrol_tertiary_pct\": 70.0\n",
    "}])\n",
    "\n",
    "# Step 3: Predict score\n",
    "predicted_score_2024 = log_model.predict(input_row_2024)[0]\n",
    "print(f\"ðŸŽ“ Predicted university score for United States in 2024 (GDP-based): {predicted_score_2024:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee1b62-fbf2-4643-948f-938574b9327f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bb5f59a-5b08-4f12-b855-509ec401385d",
   "metadata": {},
   "source": [
    "## Total Score Prediction for 2023 Using Baseline and ARIMA Forecasting Models \n",
    "\n",
    "### Methods\n",
    "- Moving Average\n",
    "\n",
    "- Exponential Smoothing\n",
    "\n",
    "- Holt-Winters (with trend & seasonality)\n",
    "\n",
    "- ARIMA Choose parameters (p,d,q) using AIC/BIC, Forecast 2023 scores for each country\n",
    "\n",
    "Include model selection, residual diagnostics, and forecast performance plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7587ca8-5cca-4a7b-9e94-2f38420bf8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6305755e-e863-43b7-be69-4882ab18bb19",
   "metadata": {},
   "source": [
    "### Outputs\n",
    "\n",
    "Forecast 2023 total score for each of top 10 countries. Compare predictions to actual 2023. \n",
    "\n",
    "Forecast Outputs Summarize predictions for 2024 from all models (as described in the comparison table above):\n",
    "\n",
    "Plot bar graphs or line charts showing:\n",
    "\n",
    "Predicted vs. actual, Model uncertainty (for Monte Carlo, Prophet, ARIMAX)\n",
    "\n",
    "Model Evaluation If actual 2024 data is available: Use MAE, RMSE, and MAPE as metrics.\n",
    "\n",
    "Compare performance across countries and models. Example Discussion Points: \"Monte Carlo and ARIMAX produced the lowest MAE for high-ranking countries.\" \"Prophet struggled in countries with unstable GDP trends.\" \"Linear trend was consistent but less sensitive to economic shifts.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620dc7ba-0ddb-4a63-b278-8ae0ef2e0a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7ebadf2d-1764-4735-9425-2790ee6f9a53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top10_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# ---- 4) Run both & build comparison table ----\u001b[39;00m\n\u001b[32m     65\u001b[39m STEPS = \u001b[32m2\u001b[39m  \u001b[38;5;66;03m# forecast next 2 years beyond each country's last observed year\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m ma_preds  = moving_average_forecast(top10_df, window=\u001b[32m3\u001b[39m, steps=STEPS)\n\u001b[32m     67\u001b[39m lin_preds = linear_trend_forecast(top10_df, steps=STEPS)\n\u001b[32m     69\u001b[39m rows = []\n",
      "\u001b[31mNameError\u001b[39m: name 'top10_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Forecasting by moving average and linear forecast\n",
    "\n",
    "# ---- 1) Time-index helpers ----\n",
    "def yearly_series(group, value_col=\"total_score\"):\n",
    "    \"\"\"Regular annual PeriodIndex series with freq=Y-DEC. Interpolates gaps.\"\"\"\n",
    "    g = group.sort_values(\"year\")\n",
    "    s = g.set_index(pd.PeriodIndex(g[\"year\"].astype(int), freq=\"Y-DEC\"))[value_col]\n",
    "    s = s.asfreq(\"Y-DEC\")\n",
    "    if s.isna().any():\n",
    "        s = s.interpolate(limit_direction=\"both\")\n",
    "    return s\n",
    "    \n",
    "def future_index(s, steps):\n",
    "    \"\"\"Future yearly PeriodIndex aligned to s.frequency.\"\"\"\n",
    "    return pd.period_range(s.index[-1] + 1, periods=steps, freq=s.index.freq)\n",
    "\n",
    "# ---- 2) Moving Average forecast ----\n",
    "def moving_average_forecast(df, window=3, steps=2):\n",
    "    results = {}\n",
    "    for c, g in df.groupby(\"country\"):\n",
    "        s = yearly_series(g)\n",
    "        if len(s) == 0:\n",
    "            # empty guard\n",
    "            idx = pd.period_range(2000, periods=steps, freq=\"Y-DEC\")\n",
    "            results[c] = pd.Series([np.nan]*steps, index=idx)\n",
    "            continue\n",
    "        w = max(1, min(window, len(s)))\n",
    "        ma_last = s.rolling(w).mean().iloc[-1]\n",
    "        idx = future_index(s, steps)\n",
    "        results[c] = pd.Series([ma_last]*steps, index=idx)\n",
    "    return results\n",
    "\n",
    "# ---- 3) Linear Trend Extrapolation (no sklearn; pure NumPy) ----\n",
    "def linear_trend_forecast(df, steps=2):\n",
    "    results = {}\n",
    "    for c, g in df.groupby(\"country\"):\n",
    "        g = g.sort_values(\"year\")\n",
    "        years = g[\"year\"].astype(int).values\n",
    "        y = g[\"total_score\"].values\n",
    "\n",
    "        if len(y) < 2:\n",
    "            # fallback to last observed value if too short\n",
    "            last = y[-1] if len(y) else np.nan\n",
    "            last_year = years[-1] if len(years) else 2023\n",
    "            fut_years = np.arange(last_year+1, last_year+1+steps)\n",
    "            idx = pd.PeriodIndex(fut_years, freq=\"Y-DEC\")\n",
    "            results[c] = pd.Series([last]*steps, index=idx)\n",
    "            continue\n",
    "\n",
    "        # center years for numerical stability\n",
    "        base = years.min()\n",
    "        x = (years - base).astype(float)\n",
    "        # fit y = a*x + b\n",
    "        a, b = np.polyfit(x, y, 1)\n",
    "\n",
    "        last_year = years[-1]\n",
    "        fut_years = np.arange(last_year+1, last_year+1+steps)\n",
    "        x_future = (fut_years - base).astype(float)\n",
    "        preds = a * x_future + b\n",
    "        idx = pd.PeriodIndex(fut_years, freq=\"Y-DEC\")\n",
    "        results[c] = pd.Series(preds, index=idx)\n",
    "    return results\n",
    "\n",
    "# ---- 4) Run both & build comparison table ----\n",
    "STEPS = 2  # forecast next 2 years beyond each country's last observed year\n",
    "ma_preds  = moving_average_forecast(top10_df, window=3, steps=STEPS)\n",
    "lin_preds = linear_trend_forecast(top10_df, steps=STEPS)\n",
    "\n",
    "rows = []\n",
    "for c in top10_countries:\n",
    "    # Use linear trend index for naming (both methods share same future years count)\n",
    "    idx = lin_preds[c].index\n",
    "    row = {\"country\": c}\n",
    "    for i in range(STEPS):\n",
    "        y = idx[i].year\n",
    "        row[f\"MA_{y}\"]  = ma_preds[c].iloc[i]  if len(ma_preds[c])  > i else np.nan\n",
    "        row[f\"LIN_{y}\"] = lin_preds[c].iloc[i] if len(lin_preds[c]) > i else np.nan\n",
    "    rows.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(rows).sort_values(\"country\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac769f53-3855-4cbb-8100-da24d43a7620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e4406-40ff-4ad7-8366-0b171cf7e763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting using ARIMA\n",
    "\n",
    "def arima_forecast(df, steps=2, order=(1,1,0)):\n",
    "    \"\"\"\n",
    "    ARIMA forecast for total_score per country.\n",
    "    order=(p,d,q):\n",
    "        p - AR order\n",
    "        d - differencing order\n",
    "        q - MA order\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for c, g in df.groupby(\"country\"):\n",
    "        s = yearly_series(g)  # from your helper â€” gives annual PeriodIndex, interpolated\n",
    "\n",
    "        if s.isna().all() or len(s) < (order[0] + order[2] + 1):\n",
    "            # fallback: repeat last value\n",
    "            last_val = s.iloc[-1] if len(s) else np.nan\n",
    "            idx = future_index(s, steps)\n",
    "            results[c] = pd.Series([last_val] * steps, index=idx)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Fit ARIMA model\n",
    "            model = ARIMA(s, order=order)\n",
    "            fitted = model.fit()\n",
    "\n",
    "            # Forecast\n",
    "            forecast = fitted.forecast(steps=steps)\n",
    "            idx = future_index(s, steps)\n",
    "            results[c] = pd.Series(forecast.values, index=idx)\n",
    "        except Exception as e:\n",
    "            # Fallback on error\n",
    "            last_val = s.iloc[-1]\n",
    "            idx = future_index(s, steps)\n",
    "            results[c] = pd.Series([last_val] * steps, index=idx)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7208b5-a56e-4966-9615-8bc854cd28fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 2\n",
    "ma_preds  = moving_average_forecast(top10_df, window=3, steps=STEPS)\n",
    "lin_preds = linear_trend_forecast(top10_df, steps=STEPS)\n",
    "arima_preds = arima_forecast(top10_df, steps=STEPS, order=(1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9255fd4-1b2f-4018-8f02-5c1d1afd1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for c in top10_countries:\n",
    "    idx = lin_preds[c].index  # consistent years\n",
    "    row = {\"country\": c}\n",
    "    for i in range(STEPS):\n",
    "        y = idx[i].year\n",
    "        row[f\"MA_{y}\"]    = ma_preds[c].iloc[i]    if len(ma_preds[c]) > i else np.nan\n",
    "        row[f\"LIN_{y}\"]   = lin_preds[c].iloc[i]   if len(lin_preds[c]) > i else np.nan\n",
    "        row[f\"ARIMA_{y}\"] = arima_preds[c].iloc[i] if len(arima_preds[c]) > i else np.nan\n",
    "    rows.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(rows).sort_values(\"country\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5349f-717a-49d0-aa73-6cbbd838cf94",
   "metadata": {},
   "source": [
    "## Comparision Predicted vs Actuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f0afa-6e20-42a3-8e48-e9ca6246a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank_2023 = pd.read_csv(\"data/2023 QS World University Rankings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20e08a-7aa8-4e54-a065-8350fce80e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank_2024 = pd.read_csv(\"data/2024 QS World University Rankings 1.1 (For qs.com).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a0709-aed2-4e3a-ba8a-8e54861ef241",
   "metadata": {},
   "source": [
    "### Data Cleaning and Feature Engineering\n",
    "Data for the year 2017 to 2022 contain 15 columns with 6482 entries.\n",
    "Data for the year 2023 contain 21 columns with 1422 entries.\n",
    "Data for the year 2023 has 6 more columns than the data for the year 2017 to 2022. Data from 2017 to 2022 has more entries because it consists of 5 year rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3d152-7274-4110-8ce4-37310c48dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate columns from both data\n",
    "columns1 = df_rank.columns # columns from data 2017-2022 \n",
    "columns2 = df_rank_2023.columns # columns from data 2023 \n",
    "\n",
    "print(\"columns from data 2017-2022:\", columns1)\n",
    "print(\"columns from data 2023 :\", columns2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcc2e03-a458-4712-9161-95dcf0b44f20",
   "metadata": {},
   "source": [
    "Data has different column names but actually multiple columns contain the same information. Common column pair:\n",
    "\n",
    "'university'='institution' 'rank_display'='Rank' 'score'='score scaled' 'country'='location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8dad26-ba34-49d3-b0a7-0852fe727f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy selected columns from Data 2023\n",
    "df_temp2023 = df_rank_2023[['institution','Rank','score scaled','location']].copy()\n",
    "# add year column\n",
    "df_temp2023['year'] = 2023\n",
    "# Check result\n",
    "df_temp2023.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01c0b7-2d65-4bd3-8d71-5c8e39a3b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp2023.columns = ['university','rank_display','score','country', 'year']\n",
    "# Check result\n",
    "df_temp2023.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545c11f-66ce-4e16-85cb-ecd0f16c2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rank_display to numeric \n",
    "df_temp2023['rank_display'] = pd.to_numeric(df_temp2023['rank_display'], errors='coerce')\n",
    "\n",
    "# Filter top 300 for each year\n",
    "df_top300_2023 = df_temp2023[df_temp2023['rank_display'] <= 300]\n",
    "\n",
    "# Count missing scores\n",
    "missing_count = df_top300_2023['score'].isna().sum()\n",
    "total_count = len(df_top300_2023)\n",
    "missing_percentage = (missing_count / total_count) * 100\n",
    "\n",
    "print(f\"Total entries in top 300: {total_count}\")\n",
    "print(f\"Missing score entries: {missing_count}\")\n",
    "print(f\"Missing percentage: {missing_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3833f85-4267-4ae7-b95e-2fc954ba9a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rank_display to numeric \n",
    "df_temp2023['rank_display'] = pd.to_numeric(df_temp2023['rank_display'], errors='coerce')\n",
    "\n",
    "# Filter top 300 for each year\n",
    "df_top300_2023 = df_temp2023[df_temp2023['rank_display'] <= 300]\n",
    "\n",
    "# Count missing scores\n",
    "missing_count = df_top300_2023['score'].isna().sum()\n",
    "total_count = len(df_top300_2023)\n",
    "missing_percentage = (missing_count / total_count) * 100\n",
    "\n",
    "print(f\"Total entries in top 300: {total_count}\")\n",
    "print(f\"Missing score entries: {missing_count}\")\n",
    "print(f\"Missing percentage: {missing_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ec407-9763-4928-b9e7-b761d2de7619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab20e8-7426-461e-9002-6c9e9093c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rank_display to numeric \n",
    "df_temp2023['rank_display'] = pd.to_numeric(df_temp2023['rank_display'], errors='coerce')\n",
    "\n",
    "# Filter top 300 for each year\n",
    "df_top300_2023 = df_temp2023[df_temp2023['rank_display'] <= 300]\n",
    "\n",
    "# Count missing scores\n",
    "missing_count = df_top300_2023['score'].isna().sum()\n",
    "total_count = len(df_top300_2023)\n",
    "missing_percentage = (missing_count / total_count) * 100\n",
    "\n",
    "print(f\"Total entries in top 300: {total_count}\")\n",
    "print(f\"Missing score entries: {missing_count}\")\n",
    "print(f\"Missing percentage: {missing_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42a1d6-df66-41d0-914b-c45e1c2c9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8bc33-79df-4937-8400-94e209d571b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One row per (year, country)\n",
    "assert agg_df_yr_country.duplicated([\"year\", \"country\"]).sum() == 0\n",
    "\n",
    "# All top10 countries appear in actuals (unless missing in 2023)\n",
    "print(set(top10_countries) - set(actuals_2023[\"country\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5475e432-94b2-470e-aaf5-21a5e06b1761",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[\"country\"] = comparison_df[\"country\"].astype(str).str.strip()\n",
    "actuals_2023[\"country\"]  = actuals_2023[\"country\"].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4748e-654a-4a0f-b60f-fcd4f9fc39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"actual_2023\" in comparison_df.columns:\n",
    "    comparison_df = comparison_df.drop(columns=[\"actual_2023\"])\n",
    "\n",
    "comparison_df = comparison_df.merge(actuals_2023, on=\"country\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379af2c-a30c-4d7f-89be-97611c416062",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab26a9-500a-432d-bb1e-e1d7a772154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant columns\n",
    "comparison_df = comparison_df.drop(columns=[\"actual_2023_x\", \"actual_2023_y\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad051464-821b-4838-88d4-939c3dbd5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a2a83-09de-4923-97d6-783f484d70b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"MA\", \"LIN\", \"ARIMA\"]:\n",
    "    comparison_df[f\"{model}_abs_error_2023\"] = (comparison_df[f\"{model}_2023\"] - comparison_df[\"actual_2023\"]).abs()\n",
    "    comparison_df[f\"{model}_pct_error_2023\"] = (\n",
    "        (comparison_df[f\"{model}_2023\"] - comparison_df[\"actual_2023\"]).abs() / comparison_df[\"actual_2023\"] * 100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659d9e5-dccc-42c0-8722-2fa53352eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_errors = comparison_df[\n",
    "    [col for col in comparison_df.columns if \"pct_error_2023\" in col]\n",
    "].mean().sort_values()\n",
    "\n",
    "print(avg_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d519714-47f6-48a7-959b-94b17b2d4283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4635b8ad-dc63-40cf-bf6a-03516944a9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011dab9-7315-4743-b11a-66f44163be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1) Pick Top-10 countries by avg total_score (2017â€“2022) ---\n",
    "top10_countries = (\n",
    "    train_df.groupby(\"country\")[\"total_score\"]\n",
    "            .mean()\n",
    "            .sort_values(ascending=False)\n",
    "            .head(10)\n",
    "            .index\n",
    "            .tolist()\n",
    ")\n",
    "print(\"Top 10 countries by avg total_score:\", top10_countries)\n",
    "\n",
    "# --- 2) Get 2023 GDP for Top-10, carry-forward 2022 GDP if missing ---\n",
    "pred_top10_2023 = pred_df[(pred_df[\"year\"] == 2023) & (pred_df[\"country\"].isin(top10_countries))][[\"country\", \"year\", \"gdp_per_capita\"]].copy()\n",
    "\n",
    "missing_top10 = sorted(set(top10_countries) - set(pred_top10_2023[\"country\"].unique()))\n",
    "if missing_top10:\n",
    "    gdp_2022 = (\n",
    "        train_df[(train_df[\"year\"] == 2022) & (train_df[\"country\"].isin(missing_top10))]\n",
    "        [[\"country\", \"gdp_per_capita\"]]\n",
    "        .copy()\n",
    "    )\n",
    "    if not gdp_2022.empty:\n",
    "        gdp_2022[\"year\"] = 2023\n",
    "        pred_top10_2023 = pd.concat([pred_top10_2023, gdp_2022], ignore_index=True)\n",
    "\n",
    "# --- 3) Filter training data for Top-10 only ---\n",
    "train_top10 = train_df[train_df[\"country\"].isin(top10_countries)].copy()\n",
    "\n",
    "# --- 4) Fit linear regression using only GDP ---\n",
    "X_train_gdp = train_top10[[\"gdp_per_capita\"]]\n",
    "y_train = train_top10[\"total_score\"]\n",
    "\n",
    "model_gdp = LinearRegression()\n",
    "model_gdp.fit(X_train_gdp, y_train)\n",
    "\n",
    "# --- 5) Predict 2023 total_score ---\n",
    "pred_top10_2023[\"pred_total_score_gdp\"] = model_gdp.predict(pred_top10_2023[[\"gdp_per_capita\"]])\n",
    "\n",
    "# --- 6) Sort predictions ---\n",
    "pred_top10_2023 = pred_top10_2023.sort_values(\"pred_total_score_gdp\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Show results\n",
    "print(\"\\nPredictions for 2023 (GDP only):\")\n",
    "print(pred_top10_2023)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
