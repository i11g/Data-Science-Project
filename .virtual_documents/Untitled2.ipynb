


def build_top10_per_year(df_long, value_col, top_n=10):
    """
    From a long-format dataframe with [country, year, value_col],
    return top-N countries per year based on value_col.
    """
    return (
        df_long
        .sort_values(["year", value_col], ascending=[True, False])
        .groupby("year")
        .head(top_n)
        .reset_index(drop=True)
    )

# --- Example for GDP ---
top10_gdp = build_top10_per_year(gdp_pc_long, "gdp_per_capita")

# --- Example for Gov. Effectiveness ---
top10_gov_eff = build_top10_per_year(gov_long, "gov_effectiveness")

# --- Example for R&D ---
top10_rd = build_top10_per_year(rd_long, "rd_exp_gdp")

# --- Example for Gov. Spending on Education ---
top10_edu_spend = build_top10_per_year(edu_long, "gov_edu_exp")


# --- 0) Helper: Top-N per year ---
def build_topn_per_year(df, value_col, n=10, ascending=False, year_col="year", country_col="country"):
    """
    Returns Top-N rows per year by `value_col`.
    Assumes df has [country, year, value_col].
    """
    return (
        df.sort_values([year_col, value_col], ascending=[True, ascending])
          .groupby(year_col, group_keys=False)
          .head(n)
          .reset_index(drop=True)
    )

# --- 1) Define your long-format sources & columns (adjust names if needed) ---
# Must be long dataframes with columns: ["country","year", <value_col>]
# total_score_df must have ["country","year","total_score","num_universities","avg_score"]

INDICATORS = {
    "GDP":            {"df": gdp_pc_long,  "value_col": "gdp_per_capita"},
    "Gov_Effect":     {"df": gov_long, "value_col": "gov_effectiveness"},
    "R&D":            {"df": rd_long, "value_col": "rd_exp_gdp"},
    "Edu_Spending":   {"df": edu_long, "value_col": "gov_edu_exp"},
}

# QS Top-10 by TOTAL SCORE (higher is better)
top10_total_score = build_topn_per_year(total_score_df, value_col="total_score", n=10, ascending=False)[["country","year"]]

# --- 2) Build Top-10 per indicator + merge with QS totals ---
merged_top10 = {}       # merged Top-10 slices with QS stats
top10_indicator_only = {}  # just the Top-10 lists per indicator (for overlap)

for name, cfg in INDICATORS.items():
    df_long = cfg["df"]
    col = cfg["value_col"]

    # Top-10 list per year for the indicator
    top10_ind = build_topn_per_year(df_long, value_col=col, n=10, ascending=False)[["country","year"]]
    top10_indicator_only[name] = top10_ind

    # Merge with QS totals (keep only Top-10 indicator rows, enriched with QS stats)
    merged = (
        top10_ind
        .merge(df_long[["country","year",col]], on=["country","year"], how="left")
        .merge(total_score_df, on=["country","year"], how="left")  # adds total_score, num_universities, avg_score
        .rename(columns={col: f"{name.lower()}_value"})
    )
    merged_top10[name] = merged

# Example: peek one
merged_top10["GDP"].head(5)



def _yr_cols_2017_2022(df):
    yrs = []
    for c in df.columns:
        m = re.search(r'(19|20)\d{2}', str(c))
        if m:
            y = int(m.group(0))
            if 2017 <= y <= 2022:
                yrs.append((c, y))
    # sort chronologically by the year found in the name
    yrs.sort(key=lambda t: t[1])
    return [c for c, _ in yrs]

def clean_interp_2017_2022(df: pd.DataFrame):
    """
    - Finds columns whose names contain a year in [2017..2022]
    - Replaces '..' with NaN, coerces to numeric
    - Row-wise linear interpolation across 2017..2022
    - Returns (clean_df, report_df)
    """
    year_cols = _yr_cols_2017_2022(df)
    if not year_cols:
        raise ValueError("No 2017–2022 year-like columns found.")

    out = df.copy()

    # Clean and coerce
    out[year_cols] = out[year_cols].replace(r'^\s*\.\.\s*$', np.nan, regex=True)
    out[year_cols] = out[year_cols].apply(pd.to_numeric, errors="coerce")

    # Missing report (before)
    before = out[year_cols].isna().sum()
    total_before = int(before.sum())
    rows_all_na_before = int(out[year_cols].isna().all(axis=1).sum())

    # Interpolate left↔right across years
    
    out[year_cols] = out[year_cols].interpolate(axis=1, limit_direction="both")

    # Missing report (after)
    after = out[year_cols].isna().sum()
    total_after = int(after.sum())
    rows_all_na_after = int(out[year_cols].isna().all(axis=1).sum())

    report = (
        pd.DataFrame({"missing_before": before, "missing_after": after})
          .assign(reduced=lambda d: d.missing_before - d.missing_after)
    )

    # Quick summary
    print("=== Year columns (2017–2022) ===")
    print(year_cols)
    print("\n=== Missing by column (before → after, reduced) ===")
    display(report)
    print("\n=== Overall ===")
    print(f"Total NaNs BEFORE: {total_before:,}")
    print(f"Total NaNs AFTER : {total_after:,}")
    print(f"Total Reduction  : {total_before - total_after:,}")
    print(f"Rows all-NaN across year cols BEFORE: {rows_all_na_before:,}")
    print(f"Rows all-NaN across year cols AFTER : {rows_all_na_after:,}")

    return out, report

# --- Example usage on any dataset shaped like World Bank data ---
# df_gdp_clean, gdp_report = clean_interp_2017_2022(df_gdp)
# df_edu_clean, edu_report = clean_interp_2017_2022(df_edu)
# df_rnd_clean, rnd_report = clean_interp_2017_2022(df_rnd)
