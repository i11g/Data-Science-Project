import pandas as pd
import matplotlib.pyplot as plt














# Load dataset
df = pd.read_csv("qs-world-university-rankings-2017-to-2022-V2.csv")

# Clean the data
df_clean = df.dropna(subset=["country", "year", "score"]).copy()

# Convert data types safely
df_clean.loc[:, "year"] = df_clean["year"].astype(int)
df_clean.loc[:, "score"] = pd.to_numeric(df_clean["score"], errors="coerce")
df_clean = df_clean.dropna(subset=["score"]).copy()

# Strip spaces in country names
df_clean.loc[:, "country"] = df_clean["country"].str.strip()

# Group by year and country, calculate average score
avg_scores = df_clean.groupby(["year", "country"], as_index=False)["score"].mean()

# âœ… Correct usage of include_group=False (outside the lambda!)
top10_by_year = (
    avg_scores.groupby("year", group_keys=False)
    .apply(lambda x: x.sort_values("score", ascending=False).head(10))
    .reset_index(drop=True)
)

# Display results
for year in sorted(top10_by_year["year"].unique()):
    print(f"\nðŸ“… Top 10 Countries in {year}:")
    display(top10_by_year[top10_by_year["year"] == year])


df_clean.groupby(["year", "country"]).size().reset_index(name="university_count")


# Count universities per country per year
counts_per_year = (
    df_clean.groupby(["year", "country"])
    .size()
    .reset_index(name="university_count")
)

# Get top 10 countries for each year
top10_by_universities = (
    counts_per_year.groupby("year", group_keys=False)
    .apply(lambda x: x.sort_values("university_count", ascending=False).head(10))
)
top10_by_universities


# Step 1: Sort original data by year, country, and score descending
df_sorted = df_clean.sort_values(by=["year", "country", "score"], ascending=[True, True, False])

# Step 2: Get top 5 universities per country per year
df_top5 = df_sorted.groupby(["year", "country"]).head(10)

# Step 3: Compute average score from top 5
avg_top5_scores = df_top5.groupby(["year", "country"], as_index=False)["score"].mean()

# Step 4: Get top 10 countries per year
top10_by_year = (
    avg_top5_scores.groupby("year", group_keys=False)
    .apply(lambda x: x.sort_values("score", ascending=False).head(10))
    .reset_index(drop=True)    
)
# Display results
for year in sorted(top10_by_year["year"].unique()):
    print(f"\nðŸ“… Top 10 Countries in {year}:")
    display(top10_by_year[top10_by_year["year"] == year])


gdp_df = pd.read_csv("GDP.csv", skiprows=4)

# Preview the structure of the cleaned GDP dataframe
gdp_df.head()


# Step 1: Load the data and skip metadata rows
gdp_raw = pd.read_csv("GDP.csv", skiprows=3)

# Step 2: Keep only GDP per capita (current US$)
gdp_filtered = gdp_raw[gdp_raw["Indicator Name"] == "GDP per capita (current US$)"].copy()

# Step 3: Drop unneeded columns
gdp_filtered = gdp_filtered.drop(columns=["Country Code", "Indicator Name", "Indicator Code"], errors="ignore")
gdp_filtered = gdp_filtered.loc[:, ~gdp_filtered.columns.str.contains("^Unnamed")]

# Step 4: Reshape from wide to long format
gdp_long = gdp_filtered.melt(id_vars=["Country Name"], var_name="year", value_name="gdp_per_capita")

# Step 5: Clean column names and filter years
gdp_long = gdp_long.rename(columns={"Country Name": "country"})
gdp_long["year"] = pd.to_numeric(gdp_long["year"], errors="coerce")
gdp_long = gdp_long.dropna(subset=["year", "gdp_per_capita"])
gdp_long["year"] = gdp_long["year"].astype(int)

# Filter for your project years
gdp_long = gdp_long[gdp_long["year"].between(2017, 2024)]

# Final result
gdp_long.head(20)


# Merge average scores and university counts
rank_stats = pd.merge(avg_scores, counts_per_year, on=["country", "year"])


# Merge GDP with ranking stats
merged_df = pd.merge(gdp_long, rank_stats, on=["country", "year"])

# Final columns: country, year, gdp_per_capita, score, university_count
merged_df.head(20)


import matplotlib.pyplot as plt

# Filter for the country
country = "United States"
country_df = merged_df[merged_df["country"] == country]

# Create figure and first axis (GDP)
fig, ax1 = plt.subplots(figsize=(10, 6))

# Plot GDP on left y-axis
ax1.set_title(f"GDP vs Rankings - {country}")
ax1.set_xlabel("Year")
ax1.set_ylabel("GDP per Capita (USD)", color="tab:blue")
ax1.plot(country_df["year"], country_df["gdp_per_capita"], label="GDP per Capita", color="tab:blue", linewidth=2)
ax1.tick_params(axis="y", labelcolor="tab:blue")

# Create second y-axis sharing the same x-axis
ax2 = ax1.twinx()

# Plot average score and university count on right y-axis
ax2.set_ylabel("Score / University Count", color="tab:red")
ax2.plot(country_df["year"], country_df["score"], label="Avg Score", color="tab:red", linestyle="--", linewidth=2)
ax2.plot(country_df["year"], country_df["university_count"], label="# of Universities", color="tab:green", linestyle=":", linewidth=2)
ax2.tick_params(axis="y", labelcolor="tab:red")

# Combine legends from both axes
lines_1, labels_1 = ax1.get_legend_handles_labels()
lines_2, labels_2 = ax2.get_legend_handles_labels()
ax2.legend(lines_1 + lines_2, labels_1 + labels_2, loc="upper left")

# Grid and layout
ax1.grid(True)
plt.tight_layout()
plt.show()


# Compute correlation matrix
correlation = merged_df[["gdp_per_capita", "score", "university_count"]].corr()

# Display correlation table
print(correlation)


# Get top 10 countries by average score
top10_score_countries = (
    merged_df.groupby("country")["score"]
    .mean()
    .nlargest(10)
    .index
    .tolist()
)

# Get top 10 countries by total number of universities
top10_universities_countries = (
    merged_df.groupby("country")["university_count"]
    .sum()
    .nlargest(10)
    .index
    .tolist()
)

# Combine both sets
top_countries = list(set(top10_score_countries + top10_universities_countries))

# Filter merged_df for those countries only
filtered_df = merged_df[merged_df["country"].isin(top_countries)]

# Compute correlation
correlation_top = filtered_df[["gdp_per_capita", "score", "university_count"]].corr()

# Display result
print("ðŸ“Š Correlation Matrix (Top Countries):")
print(correlation_top)


from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Step 1: Prepare data (we use the same top countries DataFrame)
X = filtered_df[["gdp_per_capita"]]
y = filtered_df["score"]

# Step 2: Initialize and fit the model
model = LinearRegression()
model.fit(X, y)

# Step 3: Get coefficients
slope = model.coef_[0]
intercept = model.intercept_
r_squared = model.score(X, y)

print(f"ðŸ“ˆ Linear Regression Model:")
print(f"score = {slope:.4f} * gdp_per_capita + {intercept:.2f}")
print(f"RÂ² (explained variance): {r_squared:.4f}")


# Scatterplot + regression line
plt.figure(figsize=(8, 5))
sns.scatterplot(x="gdp_per_capita", y="score", data=filtered_df, label="Data")
plt.plot(X, model.predict(X), color="red", label="Regression Line")

plt.title("GDP per Capita vs. University Score (Top Countries)")
plt.xlabel("GDP per Capita (USD)")
plt.ylabel("Average University Score")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()


import pandas as pd

# Load your dataset
edu_df = pd.read_csv("world-education-data.csv")  # replace with actual filename

# Keep only the relevant columns
spending_df = edu_df[["country", "year", "gov_exp_pct_gdp"]].copy()

# Drop missing values (optional: you can choose to keep them too)
spending_df = spending_df.dropna(subset=["gov_exp_pct_gdp"])

# Convert year to integer
spending_df["year"] = spending_df["year"].astype(int)

# Optional: Filter for years of interest
spending_df = spending_df[spending_df["year"].between(2017, 2024)]

# View results
spending_df.head(20)


merged = pd.merge(merged_df, spending_df, on=["country", "year"], how="left")



merged[["gov_exp_pct_gdp", "score", "gdp_per_capita"]].corr()



print(merged_df.columns.tolist())


edu_df = pd.read_csv("world-education-data.csv")  # update with your actual filename

# Keep only the relevant columns
edu_features_df = edu_df[[
    "country", "year",
    "gov_exp_pct_gdp",
    "lit_rate_adult_pct",
    "school_enrol_primary_pct",
    "school_enrol_secondary_pct",
    "school_enrol_tertiary_pct"
]].copy()



merged_df = pd.merge(merged_df, edu_features_df, on=["country", "year"], how="left")


# Select only the relevant columns
columns_of_interest = [
    "score",
    "gdp_per_capita",
    "gov_exp_pct_gdp",
    "lit_rate_adult_pct",
    "school_enrol_primary_pct",
    "school_enrol_secondary_pct",
    "school_enrol_tertiary_pct"
]

# Filter the dataset
edu_corr = merged_df[columns_of_interest].dropna()

# Compute correlation
corr_matrix = edu_corr.corr()
print(corr_matrix)

# Display as heatmap
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix: Education Indicators vs Score")
plt.tight_layout()
plt.show()


from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import pandas as pd

# Step 1: Define the features and target
features = [
    "gdp_per_capita",
    "gov_exp_pct_gdp",
    "lit_rate_adult_pct",
    "school_enrol_primary_pct",
    "school_enrol_secondary_pct",
    "school_enrol_tertiary_pct"
]

# Drop missing values
model_data = merged_df.dropna(subset=features + ["score"])

# X = predictors, y = target
X = model_data[features]
y = model_data["score"]


# Fit the model
reg = LinearRegression()
reg.fit(X, y)

# Predict
y_pred = reg.predict(X)

# R-squared
r2 = r2_score(y, y_pred)

# Coefficients
print("ðŸ“Š Multiple Linear Regression Results:")
for feature, coef in zip(features, reg.coef_):
    print(f"{feature}: {coef:.4f}")
    
print(f"\nIntercept: {reg.intercept_:.2f}")
print(f"RÂ² (explained variance): {r2:.4f}")


import matplotlib.pyplot as plt

plt.figure(figsize=(6, 5))
plt.scatter(y, y_pred, alpha=0.6)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
plt.xlabel("Actual Score")
plt.ylabel("Predicted Score")
plt.title("Actual vs Predicted University Score")
plt.grid(True)
plt.tight_layout()
plt.show()



import numpy as np

# Add log-transformed GDP column
merged_df["log_gdp_per_capita"] = np.log(merged_df["gdp_per_capita"])

# Optional: confirm no -inf or NaN values
merged_df = merged_df.replace([np.inf, -np.inf], np.nan)


from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Define new feature list
log_features = [
    "log_gdp_per_capita",
    "gov_exp_pct_gdp",
    "lit_rate_adult_pct",
    "school_enrol_primary_pct",
    "school_enrol_secondary_pct",
    "school_enrol_tertiary_pct"
]

# Drop missing
log_model_data = merged_df.dropna(subset=log_features + ["score"])
X_log = log_model_data[log_features]
y_log = log_model_data["score"]

# Fit the model
log_model = LinearRegression()
log_model.fit(X_log, y_log)
y_log_pred = log_model.predict(X_log)

# Print results
print("ðŸ“Š Multiple Regression with log(GDP):")
for f, coef in zip(log_features, log_model.coef_):
    print(f"{f}: {coef:.4f}")

print(f"\nIntercept: {log_model.intercept_:.2f}")
print(f"RÂ² (explained variance): {r2_score(y_log, y_log_pred):.4f}")


from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt

# Step 1: Get GDP per capita time series for United States (2017â€“2023)
country = "United States"
gdp_series = merged_df[(merged_df["country"] == country) & (merged_df["year"] <= 2023)]
gdp_series = gdp_series.set_index("year")["gdp_per_capita"]

# Step 2: Fit ARIMA model (try (1,1,1) as a default)
model = ARIMA(gdp_series, order=(1, 1, 1))
model_fit = model.fit()

# Step 3: Forecast GDP for 2024
gdp_forecast_2024 = model_fit.forecast(steps=1)
forecasted_gdp = gdp_forecast_2024.iloc[0]

print(f"ðŸ“ˆ Forecasted GDP per capita for {country} in 2024: ${forecasted_gdp:,.2f}")


features = ['log_gdp_per_capita', 'gov_exp_pct_gdp', 'lit_rate_adult_pct',
            'school_enrol_primary_pct', 'school_enrol_secondary_pct', 'school_enrol_tertiary_pct']


merged_df[(merged_df["country"] == "United States") & (merged_df["year"] == 2024)]



import numpy as np
import pandas as pd

# Step 1: Define the features used in your log-GDP regression model
features = [
    "log_gdp_per_capita",
    "gov_exp_pct_gdp",
    "lit_rate_adult_pct",
    "school_enrol_primary_pct",
    "school_enrol_secondary_pct",
    "school_enrol_tertiary_pct"
]

# Step 2: Create a minimal input row for 2024
# Replace these values with averages or reasonable estimates
input_row_2024 = pd.DataFrame([{
    "log_gdp_per_capita": np.log(forecasted_gdp),
    "gov_exp_pct_gdp": 5.0,                  # average: ~5% of GDP
    "lit_rate_adult_pct": 99.0,              # high literacy for US
    "school_enrol_primary_pct": 102.0,       # slightly over 100% (common due to repeaters)
    "school_enrol_secondary_pct": 95.0,
    "school_enrol_tertiary_pct": 70.0
}])

# Step 3: Predict score
predicted_score_2024 = log_model.predict(input_row_2024)[0]
print(f"ðŸŽ“ Predicted university score for United States in 2024 (GDP-based): {predicted_score_2024:.2f}")

























