import numpy as np

df_rank_clean = df_rank.reset_index(drop=True).copy()
missing_idx = np.where(df_rank_clean['score'].isna())[0]
n = len(df_rank_clean)

for i in missing_idx:
    left  = df_rank_clean['score'].iloc[i-1] if i-1 >= 0 else np.nan
    right = df_rank_clean['score'].iloc[i+1] if i+1 < n   else np.nan
    df_rank_clean.at[i, 'score'] = np.nanmean([left, right])

# In case both neighbors were NaN:
df_rank_clean['score'] = df_rank_clean['score'].interpolate(limit_direction='both')


df_clean.groupby(["year", "country"]).size().reset_index(name="university_count")

















# Count universities per country per year
counts_per_year = (
    df_clean.groupby(["year", "country"])
    .size()
    .reset_index(name="university_count")
)

# Get top 10 countries for each year
top10_by_universities = (
    counts_per_year.groupby("year", group_keys=False)
    .apply(lambda x: x.sort_values("university_count", ascending=False).head(10))
)
top10_by_universities


# Step 1: Sort original data by year, country, and score descending
df_sorted = df_clean.sort_values(by=["year", "country", "score"], ascending=[True, True, False])

# Step 2: Get top 5 universities per country per year
df_top5 = df_sorted.groupby(["year", "country"]).head(10)

# Step 3: Compute average score from top 5
avg_top5_scores = df_top5.groupby(["year", "country"], as_index=False)["score"].mean()

# Step 4: Get top 10 countries per year
top10_by_year = (
    avg_top5_scores.groupby("year", group_keys=False)
    .apply(lambda x: x.sort_values("score", ascending=False).head(10))
    .reset_index(drop=True)    
)
# Display results
for year in sorted(top10_by_year["year"].unique()):
    print(f"\nðŸ“… Top 10 Countries in {year}:")
    display(top10_by_year[top10_by_year["year"] == year])


from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Step 1: Prepare data (we use the same top countries DataFrame)
X = filtered_df[["gdp_per_capita"]]
y = filtered_df["score"]

# Step 2: Initialize and fit the model
model = LinearRegression()
model.fit(X, y)

# Step 3: Get coefficients
slope = model.coef_[0]
intercept = model.intercept_
r_squared = model.score(X, y)

print(f"ðŸ“ˆ Linear Regression Model:")
print(f"score = {slope:.4f} * gdp_per_capita + {intercept:.2f}")
print(f"RÂ² (explained variance): {r_squared:.4f}")


# Scatterplot + regression line
plt.figure(figsize=(8, 5))
sns.scatterplot(x="gdp_per_capita", y="score", data=filtered_df, label="Data")
plt.plot(X, model.predict(X), color="red", label="Regression Line")

plt.title("GDP per Capita vs. University Score (Top Countries)")
plt.xlabel("GDP per Capita (USD)")
plt.ylabel("Average University Score")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()





from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Define new feature list
log_features = [
    "log_gdp_per_capita",
    "gov_exp_pct_gdp",
    "lit_rate_adult_pct",
    "school_enrol_primary_pct",
    "school_enrol_secondary_pct",
    "school_enrol_tertiary_pct"
]

# Drop missing
log_model_data = merged_df.dropna(subset=log_features + ["score"])
X_log = log_model_data[log_features]
y_log = log_model_data["score"]

# Fit the model
log_model = LinearRegression()
log_model.fit(X_log, y_log)
y_log_pred = log_model.predict(X_log)

# Print results
print("ðŸ“Š Multiple Regression with log(GDP):")
for f, coef in zip(log_features, log_model.coef_):
    print(f"{f}: {coef:.4f}")

print(f"\nIntercept: {log_model.intercept_:.2f}")
print(f"RÂ² (explained variance): {r2_score(y_log, y_log_pred):.4f}")





import numpy as np
import pandas as pd

# Step 1: Define the features used in your log-GDP regression model
features = [
    "log_gdp_per_capita",
    "gov_exp_pct_gdp",
    "lit_rate_adult_pct",
    "school_enrol_primary_pct",
    "school_enrol_secondary_pct",
    "school_enrol_tertiary_pct"
]

# Step 2: Create a minimal input row for 2024
# Replace these values with averages or reasonable estimates
input_row_2024 = pd.DataFrame([{
    "log_gdp_per_capita": np.log(forecasted_gdp),
    "gov_exp_pct_gdp": 5.0,                  # average: ~5% of GDP
    "lit_rate_adult_pct": 99.0,              # high literacy for US
    "school_enrol_primary_pct": 102.0,       # slightly over 100% (common due to repeaters)
    "school_enrol_secondary_pct": 95.0,
    "school_enrol_tertiary_pct": 70.0
}])

# Step 3: Predict score
predicted_score_2024 = log_model.predict(input_row_2024)[0]
print(f"ðŸŽ“ Predicted university score for United States in 2024 (GDP-based): {predicted_score_2024:.2f}")


















# Forecasting by moving average and linear forecast

# ---- 1) Time-index helpers ----
def yearly_series(group, value_col="total_score"):
    """Regular annual PeriodIndex series with freq=Y-DEC. Interpolates gaps."""
    g = group.sort_values("year")
    s = g.set_index(pd.PeriodIndex(g["year"].astype(int), freq="Y-DEC"))[value_col]
    s = s.asfreq("Y-DEC")
    if s.isna().any():
        s = s.interpolate(limit_direction="both")
    return s
    
def future_index(s, steps):
    """Future yearly PeriodIndex aligned to s.frequency."""
    return pd.period_range(s.index[-1] + 1, periods=steps, freq=s.index.freq)

# ---- 2) Moving Average forecast ----
def moving_average_forecast(df, window=3, steps=2):
    results = {}
    for c, g in df.groupby("country"):
        s = yearly_series(g)
        if len(s) == 0:
            # empty guard
            idx = pd.period_range(2000, periods=steps, freq="Y-DEC")
            results[c] = pd.Series([np.nan]*steps, index=idx)
            continue
        w = max(1, min(window, len(s)))
        ma_last = s.rolling(w).mean().iloc[-1]
        idx = future_index(s, steps)
        results[c] = pd.Series([ma_last]*steps, index=idx)
    return results

# ---- 3) Linear Trend Extrapolation (no sklearn; pure NumPy) ----
def linear_trend_forecast(df, steps=2):
    results = {}
    for c, g in df.groupby("country"):
        g = g.sort_values("year")
        years = g["year"].astype(int).values
        y = g["total_score"].values

        if len(y) < 2:
            # fallback to last observed value if too short
            last = y[-1] if len(y) else np.nan
            last_year = years[-1] if len(years) else 2023
            fut_years = np.arange(last_year+1, last_year+1+steps)
            idx = pd.PeriodIndex(fut_years, freq="Y-DEC")
            results[c] = pd.Series([last]*steps, index=idx)
            continue

        # center years for numerical stability
        base = years.min()
        x = (years - base).astype(float)
        # fit y = a*x + b
        a, b = np.polyfit(x, y, 1)

        last_year = years[-1]
        fut_years = np.arange(last_year+1, last_year+1+steps)
        x_future = (fut_years - base).astype(float)
        preds = a * x_future + b
        idx = pd.PeriodIndex(fut_years, freq="Y-DEC")
        results[c] = pd.Series(preds, index=idx)
    return results

# ---- 4) Run both & build comparison table ----
STEPS = 2  # forecast next 2 years beyond each country's last observed year
ma_preds  = moving_average_forecast(top10_df, window=3, steps=STEPS)
lin_preds = linear_trend_forecast(top10_df, steps=STEPS)

rows = []
for c in top10_countries:
    # Use linear trend index for naming (both methods share same future years count)
    idx = lin_preds[c].index
    row = {"country": c}
    for i in range(STEPS):
        y = idx[i].year
        row[f"MA_{y}"]  = ma_preds[c].iloc[i]  if len(ma_preds[c])  > i else np.nan
        row[f"LIN_{y}"] = lin_preds[c].iloc[i] if len(lin_preds[c]) > i else np.nan
    rows.append(row)

comparison_df = pd.DataFrame(rows).sort_values("country").reset_index(drop=True)





# Forecasting using ARIMA

def arima_forecast(df, steps=2, order=(1,1,0)):
    """
    ARIMA forecast for total_score per country.
    order=(p,d,q):
        p - AR order
        d - differencing order
        q - MA order
    """
    results = {}
    for c, g in df.groupby("country"):
        s = yearly_series(g)  # from your helper â€” gives annual PeriodIndex, interpolated

        if s.isna().all() or len(s) < (order[0] + order[2] + 1):
            # fallback: repeat last value
            last_val = s.iloc[-1] if len(s) else np.nan
            idx = future_index(s, steps)
            results[c] = pd.Series([last_val] * steps, index=idx)
            continue

        try:
            # Fit ARIMA model
            model = ARIMA(s, order=order)
            fitted = model.fit()

            # Forecast
            forecast = fitted.forecast(steps=steps)
            idx = future_index(s, steps)
            results[c] = pd.Series(forecast.values, index=idx)
        except Exception as e:
            # Fallback on error
            last_val = s.iloc[-1]
            idx = future_index(s, steps)
            results[c] = pd.Series([last_val] * steps, index=idx)
    return results


STEPS = 2
ma_preds  = moving_average_forecast(top10_df, window=3, steps=STEPS)
lin_preds = linear_trend_forecast(top10_df, steps=STEPS)
arima_preds = arima_forecast(top10_df, steps=STEPS, order=(1,1,0))


rows = []
for c in top10_countries:
    idx = lin_preds[c].index  # consistent years
    row = {"country": c}
    for i in range(STEPS):
        y = idx[i].year
        row[f"MA_{y}"]    = ma_preds[c].iloc[i]    if len(ma_preds[c]) > i else np.nan
        row[f"LIN_{y}"]   = lin_preds[c].iloc[i]   if len(lin_preds[c]) > i else np.nan
        row[f"ARIMA_{y}"] = arima_preds[c].iloc[i] if len(arima_preds[c]) > i else np.nan
    rows.append(row)

comparison_df = pd.DataFrame(rows).sort_values("country").reset_index(drop=True)





df_rank_2023 = pd.read_csv("data/2023 QS World University Rankings.csv")


df_rank_2024 = pd.read_csv("data/2024 QS World University Rankings 1.1 (For qs.com).csv")





# Investigate columns from both data
columns1 = df_rank.columns # columns from data 2017-2022 
columns2 = df_rank_2023.columns # columns from data 2023 

print("columns from data 2017-2022:", columns1)
print("columns from data 2023 :", columns2)





# copy selected columns from Data 2023
df_temp2023 = df_rank_2023[['institution','Rank','score scaled','location']].copy()
# add year column
df_temp2023['year'] = 2023
# Check result
df_temp2023.info()


df_temp2023.columns = ['university','rank_display','score','country', 'year']
# Check result
df_temp2023.info()


# Convert rank_display to numeric 
df_temp2023['rank_display'] = pd.to_numeric(df_temp2023['rank_display'], errors='coerce')

# Filter top 300 for each year
df_top300_2023 = df_temp2023[df_temp2023['rank_display'] <= 300]

# Count missing scores
missing_count = df_top300_2023['score'].isna().sum()
total_count = len(df_top300_2023)
missing_percentage = (missing_count / total_count) * 100

print(f"Total entries in top 300: {total_count}")
print(f"Missing score entries: {missing_count}")
print(f"Missing percentage: {missing_percentage:.2f}%")


# Convert rank_display to numeric 
df_temp2023['rank_display'] = pd.to_numeric(df_temp2023['rank_display'], errors='coerce')

# Filter top 300 for each year
df_top300_2023 = df_temp2023[df_temp2023['rank_display'] <= 300]

# Count missing scores
missing_count = df_top300_2023['score'].isna().sum()
total_count = len(df_top300_2023)
missing_percentage = (missing_count / total_count) * 100

print(f"Total entries in top 300: {total_count}")
print(f"Missing score entries: {missing_count}")
print(f"Missing percentage: {missing_percentage:.2f}%")





# Convert rank_display to numeric 
df_temp2023['rank_display'] = pd.to_numeric(df_temp2023['rank_display'], errors='coerce')

# Filter top 300 for each year
df_top300_2023 = df_temp2023[df_temp2023['rank_display'] <= 300]

# Count missing scores
missing_count = df_top300_2023['score'].isna().sum()
total_count = len(df_top300_2023)
missing_percentage = (missing_count / total_count) * 100

print(f"Total entries in top 300: {total_count}")
print(f"Missing score entries: {missing_count}")
print(f"Missing percentage: {missing_percentage:.2f}%")


actuals_2023


# One row per (year, country)
assert agg_df_yr_country.duplicated(["year", "country"]).sum() == 0

# All top10 countries appear in actuals (unless missing in 2023)
print(set(top10_countries) - set(actuals_2023["country"]))


comparison_df["country"] = comparison_df["country"].astype(str).str.strip()
actuals_2023["country"]  = actuals_2023["country"].astype(str).str.strip()


if "actual_2023" in comparison_df.columns:
    comparison_df = comparison_df.drop(columns=["actual_2023"])

comparison_df = comparison_df.merge(actuals_2023, on="country", how="left")


comparison_df


# Drop redundant columns
comparison_df = comparison_df.drop(columns=["actual_2023_x", "actual_2023_y"], errors="ignore")


comparison_df


for model in ["MA", "LIN", "ARIMA"]:
    comparison_df[f"{model}_abs_error_2023"] = (comparison_df[f"{model}_2023"] - comparison_df["actual_2023"]).abs()
    comparison_df[f"{model}_pct_error_2023"] = (
        (comparison_df[f"{model}_2023"] - comparison_df["actual_2023"]).abs() / comparison_df["actual_2023"] * 100
    )


avg_errors = comparison_df[
    [col for col in comparison_df.columns if "pct_error_2023" in col]
].mean().sort_values()

print(avg_errors)








from sklearn.linear_model import LinearRegression
import pandas as pd

# --- 1) Pick Top-10 countries by avg total_score (2017â€“2022) ---
top10_countries = (
    train_df.groupby("country")["total_score"]
            .mean()
            .sort_values(ascending=False)
            .head(10)
            .index
            .tolist()
)
print("Top 10 countries by avg total_score:", top10_countries)

# --- 2) Get 2023 GDP for Top-10, carry-forward 2022 GDP if missing ---
pred_top10_2023 = pred_df[(pred_df["year"] == 2023) & (pred_df["country"].isin(top10_countries))][["country", "year", "gdp_per_capita"]].copy()

missing_top10 = sorted(set(top10_countries) - set(pred_top10_2023["country"].unique()))
if missing_top10:
    gdp_2022 = (
        train_df[(train_df["year"] == 2022) & (train_df["country"].isin(missing_top10))]
        [["country", "gdp_per_capita"]]
        .copy()
    )
    if not gdp_2022.empty:
        gdp_2022["year"] = 2023
        pred_top10_2023 = pd.concat([pred_top10_2023, gdp_2022], ignore_index=True)

# --- 3) Filter training data for Top-10 only ---
train_top10 = train_df[train_df["country"].isin(top10_countries)].copy()

# --- 4) Fit linear regression using only GDP ---
X_train_gdp = train_top10[["gdp_per_capita"]]
y_train = train_top10["total_score"]

model_gdp = LinearRegression()
model_gdp.fit(X_train_gdp, y_train)

# --- 5) Predict 2023 total_score ---
pred_top10_2023["pred_total_score_gdp"] = model_gdp.predict(pred_top10_2023[["gdp_per_capita"]])

# --- 6) Sort predictions ---
pred_top10_2023 = pred_top10_2023.sort_values("pred_total_score_gdp", ascending=False).reset_index(drop=True)

# Show results
print("\nPredictions for 2023 (GDP only):")
print(pred_top10_2023)




