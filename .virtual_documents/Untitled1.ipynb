import numpy as np

df_rank_clean = df_rank.reset_index(drop=True).copy()
missing_idx = np.where(df_rank_clean['score'].isna())[0]
n = len(df_rank_clean)

for i in missing_idx:
    left  = df_rank_clean['score'].iloc[i-1] if i-1 >= 0 else np.nan
    right = df_rank_clean['score'].iloc[i+1] if i+1 < n   else np.nan
    df_rank_clean.at[i, 'score'] = np.nanmean([left, right])

# In case both neighbors were NaN:
df_rank_clean['score'] = df_rank_clean['score'].interpolate(limit_direction='both')


# Load dataset
df = pd.read_csv("qs-world-university-rankings-2017-to-2022-V2.csv")

# Clean the data
df_clean = df.dropna(subset=["country", "year", "score"]).copy()

# Convert data types safely
df_clean.loc[:, "year"] = df_clean["year"].astype(int)
df_clean.loc[:, "score"] = pd.to_numeric(df_clean["score"], errors="coerce")
df_clean = df_clean.dropna(subset=["score"]).copy()

# Strip spaces in country names
df_clean.loc[:, "country"] = df_clean["country"].str.strip()

# Group by year and country, calculate average score
avg_scores = df_clean.groupby(["year", "country"], as_index=False)["score"].mean()

# âœ… Correct usage of include_group=False (outside the lambda!)
top10_by_year = (
    avg_scores.groupby("year", group_keys=False)
    .apply(lambda x: x.sort_values("score", ascending=False).head(10))
    .reset_index(drop=True)
)

# Display results
for year in sorted(top10_by_year["year"].unique()):
    print(f"\nðŸ“… Top 10 Countries in {year}:")
    display(top10_by_year[top10_by_year["year"] == year])


df_clean.groupby(["year", "country"]).size().reset_index(name="university_count")


# Count universities per country per year
counts_per_year = (
    df_clean.groupby(["year", "country"])
    .size()
    .reset_index(name="university_count")
)

# Get top 10 countries for each year
top10_by_universities = (
    counts_per_year.groupby("year", group_keys=False)
    .apply(lambda x: x.sort_values("university_count", ascending=False).head(10))
)
top10_by_universities


# Step 1: Sort original data by year, country, and score descending
df_sorted = df_clean.sort_values(by=["year", "country", "score"], ascending=[True, True, False])

# Step 2: Get top 5 universities per country per year
df_top5 = df_sorted.groupby(["year", "country"]).head(10)

# Step 3: Compute average score from top 5
avg_top5_scores = df_top5.groupby(["year", "country"], as_index=False)["score"].mean()

# Step 4: Get top 10 countries per year
top10_by_year = (
    avg_top5_scores.groupby("year", group_keys=False)
    .apply(lambda x: x.sort_values("score", ascending=False).head(10))
    .reset_index(drop=True)    
)
# Display results
for year in sorted(top10_by_year["year"].unique()):
    print(f"\nðŸ“… Top 10 Countries in {year}:")
    display(top10_by_year[top10_by_year["year"] == year])
