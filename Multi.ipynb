{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d65d160-f89b-4948-b295-850970acbc7d",
   "metadata": {},
   "source": [
    "Motivation University rankings play a critical role in shaping international education policy, research funding, and student decision-making. While many analyses focus on institutional performance, this project shifts the lens to the country level, offering insights into how macroeconomic and social conditions influence national academic outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29447a4-f0ba-45a1-abbd-444b92a49a07",
   "metadata": {},
   "source": [
    "These datasets cover the period 2017–2022 and are reported at the country-year level, enabling direct comparison with the QS World University Rankings data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1724d165-e017-4384-b2a1-bc693bf74462",
   "metadata": {},
   "source": [
    "#### Hypothesis Testing\n",
    "\n",
    "We test:\n",
    "$$\n",
    "H_0: \\tau = 0 \\quad \\text{(no association)}\n",
    "$$\n",
    "$$\n",
    "H_1: \\tau \\neq 0 \\quad \\text{(association exists)}\n",
    "$$\n",
    "\n",
    "For large \\( n \\), significance testing uses an approximate normal distribution. Exact tests exist for small \\( n \\).\n",
    "\n",
    "#### 6. Example\n",
    "\n",
    "Suppose we have the pairs:\n",
    "\n",
    "| Obs | \\(X\\) | \\(Y\\) |\n",
    "|-----|-------|-------|\n",
    "| 1   | 12    | 30    |\n",
    "| 2   | 15    | 40    |\n",
    "| 3   | 14    | 35    |\n",
    "\n",
    "All pairs (\\(\\binom{3}{2} = 3\\)):  \n",
    "- Pair (1,2): \\( (12-15)(30-40) > 0 \\) →All pairs (\\(\\binom{3}{2} = 3\\)):  \n",
    "- Pair (1,2): \\( (12-15)(30-40) > 0 \\) → concordant  \n",
    "- Pair (1,3): \\( (12-14)(30-35) > 0 \\) → concordant  \n",
    "- Pair (2,3): \\( (15-14)(40-35) > 0 \\) → concordant  \n",
    "\n",
    "So \\( C=3, D=0 \\).  \n",
    "\n",
    "\\[\n",
    "\\tau = \\frac{3 - 0}{3} = 1\n",
    "\\]\n",
    "\n",
    "Perfect agreement in rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b6254-3d26-435c-88cd-bfeeb4825ca8",
   "metadata": {},
   "source": [
    "##### Hypothesis Testing\n",
    "\n",
    "We can test:\n",
    "\n",
    "$$\n",
    "H_0: \\rho = 0 \\quad \\text{(no monotonic relationship)}\n",
    "$$\n",
    "$$\n",
    "H_1: \\rho \\neq 0 \\quad \\text{(monotonic relationship exists)}\n",
    "$$\n",
    "\n",
    "For \\( n > 30 \\), significance testing approximates normal distribution (after Fisher transformation). For small \\( n \\), exact critical values are used.\n",
    "\n",
    "##### Advantages\n",
    "\n",
    "- Non-parametric (no distribution assumptions).  \n",
    "- Robust to outliers.  \n",
    "- Works with **ordinal data**.  \n",
    "- Detects monotonic but nonlinear relationships.  \n",
    "\n",
    "#### Example Calculation\n",
    "\n",
    "Suppose:\n",
    "Suppose:\n",
    "\n",
    "| Obs | \\(X\\) | \\(Y\\) | Rank(X) | Rank(Y) | \\(d_i\\) | \\(d_i^2\\) |\n",
    "|-----|-------|-------|---------|---------|---------|-----------|\n",
    "| 1   | 10    | 100   | 1       | 1       | 0       | 0         |\n",
    "| 2   | 20    | 300   | 2       | 3       | -1      | 1         |\n",
    "| 3   | 30    | 200   | 3       | 2       | 1       | 1         |\n",
    "| 4   | 40    | 400   | 4       | 4       | 0       | 0         |\n",
    "\n",
    "\\[\n",
    "\\sum d_i^2 = 2, \\quad n=4\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "\\rho = 1 - \\frac{6 \\cdot 2}{4(4^2 - 1)} = 1 - \\frac{12}{60} = 0.8\n",
    "\\]\n",
    "\n",
    "This indicates a **strong positive monotonic relationship**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a290d2-1e97-4490-8cb2-09aebdf51774",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Assuming:\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# rd_exp_long → cleaned dataset with ['country', 'year', 'rd_exp_gdp']\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# merged_df   → main dataset with ['country', 'year', 'total_score']\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# --- Merge R&D data into main dataset ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m merged_rd = pd.merge(\n\u001b[32m      7\u001b[39m     merged_df,\n\u001b[32m      8\u001b[39m     rd_exp_long,\n\u001b[32m      9\u001b[39m     on=[\u001b[33m\"\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     10\u001b[39m     how=\u001b[33m\"\u001b[39m\u001b[33minner\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Ensure numeric types\u001b[39;00m\n\u001b[32m     14\u001b[39m merged_rd[\u001b[33m'\u001b[39m\u001b[33mtotal_score\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(merged_rd[\u001b[33m'\u001b[39m\u001b[33mtotal_score\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming:\n",
    "# rd_exp_long → cleaned dataset with ['country', 'year', 'rd_exp_gdp']\n",
    "# merged_df   → main dataset with ['country', 'year', 'total_score']\n",
    "\n",
    "# --- Merge R&D data into main dataset ---\n",
    "merged_rd = pd.merge(\n",
    "    merged_df,\n",
    "    rd_exp_long,\n",
    "    on=[\"country\", \"year\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Ensure numeric types\n",
    "merged_rd['total_score'] = pd.to_numeric(merged_rd['total_score'], errors='coerce')\n",
    "merged_rd['rd_exp_gdp'] = pd.to_numeric(merged_rd['rd_exp_gdp'], errors='coerce')\n",
    "\n",
    "# Drop NaNs\n",
    "corr_df = merged_rd.dropna(subset=['total_score', 'rd_exp_gdp'])\n",
    "\n",
    "# --- Pearson ---\n",
    "pearson_corr, pearson_p = pearsonr(corr_df['total_score'], corr_df['rd_exp_gdp'])\n",
    "\n",
    "# --- Spearman ---\n",
    "spearman_corr, spearman_p = spearmanr(corr_df['total_score'], corr_df['rd_exp_gdp'])\n",
    "\n",
    "# --- Kendall ---\n",
    "kendall_corr, kendall_p = kendalltau(corr_df['total_score'], corr_df['rd_exp_gdp'])\n",
    "\n",
    "# --- Print ---\n",
    "print(\"=== Correlation with R&D Expenditure (% of GDP) ===\")\n",
    "print(f\"Pearson:  r = {pearson_corr:.4f}, p = {pearson_p:.4g}\")\n",
    "print(f\"Spearman: rho = {spearman_corr:.4f}, p = {spearman_p:.4g}\")\n",
    "print(f\"Kendall:  tau = {kendall_corr:.4f}, p = {kendall_p:.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5463fb2-f726-4abc-b9ab-ac068cab9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numeric\n",
    "merged_df_edu['total_score'] = pd.to_numeric(merged_df_edu['total_score'], errors='coerce')\n",
    "merged_df_edu['gov_exp_edu'] = pd.to_numeric(merged_df_edu['gov_exp_edu'], errors='coerce')\n",
    "\n",
    "# Drop missing rows\n",
    "corr_df = merged_df_edu.dropna(subset=['total_score', 'gov_exp_edu'])\n",
    "\n",
    "# Pearson\n",
    "pearson_corr, pearson_p = pearsonr(corr_df['total_score'], corr_df['gov_exp_edu'])\n",
    "\n",
    "# Spearman\n",
    "spearman_corr, spearman_p = spearmanr(corr_df['total_score'], corr_df['gov_exp_edu'])\n",
    "\n",
    "# Kendall\n",
    "kendall_corr, kendall_p = kendalltau(corr_df['total_score'], corr_df['gov_exp_edu'])\n",
    "\n",
    "print(\"=== Correlation with Government Expenditure on Education ===\")\n",
    "print(f\"Pearson:  r = {pearson_corr:.4f}, p = {pearson_p:.4g}\")\n",
    "print(f\"Spearman: rho = {spearman_corr:.4f}, p = {spearman_p:.4g}\")\n",
    "print(f\"Kendall:  tau = {kendall_corr:.4f}, p = {kendall_p:.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7bcff3-81a2-4b19-b0b9-be7d49f4a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numeric\n",
    "merged_df_edu['total_score'] = pd.to_numeric(merged_df_edu['total_score'], errors='coerce')\n",
    "merged_df_edu['gov_exp_edu'] = pd.to_numeric(merged_df_edu['gov_exp_edu'], errors='coerce')\n",
    "\n",
    "# Drop missing rows\n",
    "corr_df = merged_df_edu.dropna(subset=['total_score', 'gov_exp_edu'])\n",
    "\n",
    "# Pearson\n",
    "pearson_corr, pearson_p = pearsonr(corr_df['total_score'], corr_df['gov_exp_edu'])\n",
    "\n",
    "# Spearman\n",
    "spearman_corr, spearman_p = spearmanr(corr_df['total_score'], corr_df['gov_exp_edu'])\n",
    "\n",
    "# Kendall\n",
    "kendall_corr, kendall_p = kendalltau(corr_df['total_score'], corr_df['gov_exp_edu'])\n",
    "\n",
    "print(\"=== Correlation with Government Expenditure on Education ===\")\n",
    "print(f\"Pearson:  r = {pearson_corr:.4f}, p = {pearson_p:.4g}\")\n",
    "print(f\"Spearman: rho = {spearman_corr:.4f}, p = {spearman_p:.4g}\")\n",
    "print(f\"Kendall:  tau = {kendall_corr:.4f}, p = {kendall_p:.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c741d4-d641-40ed-a5c7-3fefca59393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numeric\n",
    "merged_df_gov['total_score'] = pd.to_numeric(merged_df_gov['total_score'], errors='coerce')\n",
    "merged_df_gov['gov_effectiveness'] = pd.to_numeric(merged_df_gov['gov_effectiveness'], errors='coerce')\n",
    "\n",
    "# Drop missing rows\n",
    "corr_df = merged_df_gov.dropna(subset=['total_score', 'gov_effectiveness'])\n",
    "\n",
    "# Pearson\n",
    "pearson_corr, pearson_p = pearsonr(corr_df['total_score'], corr_df['gov_effectiveness'])\n",
    "\n",
    "# Spearman\n",
    "spearman_corr, spearman_p = spearmanr(corr_df['total_score'], corr_df['gov_effectiveness'])\n",
    "\n",
    "# Kendall\n",
    "kendall_corr, kendall_p = kendalltau(corr_df['total_score'], corr_df['gov_effectiveness'])\n",
    "\n",
    "print(\"=== Correlation with Government Effectiveness ===\")\n",
    "print(f\"Pearson:  r = {pearson_corr:.4f}, p = {pearson_p:.4g}\")\n",
    "print(f\"Spearman: rho = {spearman_corr:.4f}, p = {spearman_p:.4g}\")\n",
    "print(f\"Kendall:  tau = {kendall_corr:.4f}, p = {kendall_p:.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e6e44-96e7-4e75-b7e6-ee28487f84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numeric\n",
    "merged_df_gov['total_score'] = pd.to_numeric(merged_df_gov['total_score'], errors='coerce')\n",
    "merged_df_gov['gov_effectiveness'] = pd.to_numeric(merged_df_gov['gov_effectiveness'], errors='coerce')\n",
    "\n",
    "# Drop missing rows\n",
    "corr_df = merged_df_gov.dropna(subset=['total_score', 'gov_effectiveness'])\n",
    "\n",
    "# Pearson\n",
    "pearson_corr, pearson_p = pearsonr(corr_df['total_score'], corr_df['gov_effectiveness'])\n",
    "\n",
    "# Spearman\n",
    "spearman_corr, spearman_p = spearmanr(corr_df['total_score'], corr_df['gov_effectiveness'])\n",
    "\n",
    "# Kendall\n",
    "kendall_corr, kendall_p = kendalltau(corr_df['total_score'], corr_df['gov_effectiveness'])\n",
    "\n",
    "print(\"=== Correlation with Government Effectiveness ===\")\n",
    "print(f\"Pearson:  r = {pearson_corr:.4f}, p = {pearson_p:.4g}\")\n",
    "print(f\"Spearman: rho = {spearman_corr:.4f}, p = {spearman_p:.4g}\")\n",
    "print(f\"Kendall:  tau = {kendall_corr:.4f}, p = {kendall_p:.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e20b5-8175-48c0-a72e-ed9fca21f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_secondary[\"source\"] = \"primary\"\n",
    "top10_total_score[\"source\"] = \"Total_Score\"\n",
    "\n",
    "# Merge both lists\n",
    "comparison_df = pd.concat([top10_secondary, top10_total_score], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a7129a-5d5d-475a-add0-ad093b4e26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_secondary[\"source\"] = \"primary\"\n",
    "top10_total_score[\"source\"] = \"Total_Score\"\n",
    "\n",
    "# Merge both lists\n",
    "comparison_df = pd.concat([top10_secondary, top10_total_score], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a36f7-68b3-4d35-b658-01b91922bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_secondary[\"source\"] = \"primary\"\n",
    "top10_total_score[\"source\"] = \"Total_Score\"\n",
    "\n",
    "# Merge both lists\n",
    "comparison_df = pd.concat([top10_secondary, top10_total_score], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5953993-39c7-4534-a2a7-8f01a380cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize totals\n",
    "total_overlap_sum = 0\n",
    "total_baseline_sum = 0\n",
    "\n",
    "# For the unique-country summary across the whole period:\n",
    "all_overlap_countries = set()\n",
    "all_union_countries = set()\n",
    "\n",
    "for year in sorted(comparison_df[\"year\"].unique()):\n",
    "    # --- Select countries for this year ---\n",
    "    secondary_countries = set(top10_secondary[top10_secondary[\"year\"] == year][\"country\"])\n",
    "    score_countries     = set(top10_total_score[top10_total_score[\"year\"] == year][\"country\"])\n",
    "    \n",
    "    # --- Calculate overlap ---\n",
    "    overlap = secondary_countries & score_countries\n",
    "    \n",
    "    # --- Yearly percentage (vs total_score list size) ---\n",
    "    overlap_pct = (len(overlap) / len(score_countries) * 100) if len(score_countries) else 0.0\n",
    "    \n",
    "    # --- Print per-year ---\n",
    "    print(f\"{year} → Overlap: {len(overlap)} countries ({overlap_pct:.1f}%) → {sorted(overlap)}\")\n",
    "    \n",
    "    # --- Accumulate for sum-based total ---\n",
    "    total_overlap_sum  += len(overlap)\n",
    "    total_baseline_sum += len(score_countries)  \n",
    "    \n",
    "    # --- Accumulate for unique-country total ---\n",
    "    all_overlap_countries |= overlap\n",
    "    all_union_countries   |= (secondary_countries | score_countries)\n",
    "\n",
    "# --- Sum-based total ---\n",
    "if total_baseline_sum > 0:\n",
    "    total_pct_sum = total_overlap_sum / total_baseline_sum * 100\n",
    "else:\n",
    "    total_pct_sum = 0.0\n",
    "\n",
    "print(\"\\n=== TOTAL (sum-based) ===\")\n",
    "print(f\"Overlaps: {total_overlap_sum} over baseline {total_baseline_sum} → {total_pct_sum:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490906a9-e921-4551-a98b-af83b80d3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_tertiary[\"source\"] = \"primary\"\n",
    "top10_total_score[\"source\"] = \"Total_Score\"\n",
    "\n",
    "# Merge both lists\n",
    "comparison_df = pd.concat([top10_tertiary, top10_total_score], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30358eb3-857c-4418-a11b-0b988301b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_overlap_sum = 0        # sum of overlaps across years\n",
    "total_baseline_sum = 0       # sum of denominator sizes across years (here: score_countries)\n",
    "\n",
    "# For the unique-country summary across the whole period:\n",
    "all_overlap_countries = set()\n",
    "all_union_countries = set()\n",
    "\n",
    "for year in sorted(comparison_df[\"year\"].unique()):\n",
    "    # --- Select countries for this year ---\n",
    "    tertiary_countries = set(top10_tertiary[top10_tertiary[\"year\"] == year][\"country\"])\n",
    "    score_countries    = set(top10_total_score[top10_total_score[\"year\"] == year][\"country\"])\n",
    "    \n",
    "    # --- Yearly overlap ---\n",
    "    overlap = tertiary_countries & score_countries\n",
    "    \n",
    "    # --- Yearly percentage (vs total_score list size) ---\n",
    "    overlap_pct = (len(overlap) / len(score_countries) * 100) if len(score_countries) else 0.0\n",
    "    \n",
    "    # --- Print per-year ---\n",
    "    print(f\"{year} → Overlap: {len(overlap)} countries ({overlap_pct:.1f}%) → {sorted(overlap)}\")\n",
    "    \n",
    "    # --- Accumulate for sum-based total ---\n",
    "    total_overlap_sum  += len(overlap)\n",
    "    total_baseline_sum += len(score_countries)  # change to len(tertiary_countries) if you prefer that baseline\n",
    "    \n",
    "    # --- Accumulate for unique-country total ---\n",
    "    all_overlap_countries |= overlap\n",
    "    all_union_countries   |= (tertiary_countries | score_countries)\n",
    "\n",
    "# --- Sum-based total (e.g., '16 overlaps over 70 countries') ---\n",
    "if total_baseline_sum > 0:\n",
    "    total_pct_sum = total_overlap_sum / total_baseline_sum * 100\n",
    "else:\n",
    "    total_pct_sum = 0.0\n",
    "\n",
    "print(\"\\n=== TOTAL (sum-based) ===\")\n",
    "print(f\"Overlaps: {total_overlap_sum} over baseline {total_baseline_sum} → {total_pct_sum:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa92e51-8a4a-4116-a781-67309af9f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_overlap_sum = 0        # sum of overlaps across years\n",
    "total_baseline_sum = 0       # sum of denominator sizes across years (here: score_countries)\n",
    "\n",
    "# For the unique-country summary across the whole period:\n",
    "all_overlap_countries = set()\n",
    "all_union_countries = set()\n",
    "\n",
    "for year in sorted(comparison_df[\"year\"].unique()):\n",
    "    # --- Select countries for this year ---\n",
    "    tertiary_countries = set(top10_tertiary[top10_tertiary[\"year\"] == year][\"country\"])\n",
    "    score_countries    = set(top10_total_score[top10_total_score[\"year\"] == year][\"country\"])\n",
    "    \n",
    "    # --- Yearly overlap ---\n",
    "    overlap = tertiary_countries & score_countries\n",
    "    \n",
    "    # --- Yearly percentage (vs total_score list size) ---\n",
    "    overlap_pct = (len(overlap) / len(score_countries) * 100) if len(score_countries) else 0.0\n",
    "    \n",
    "    # --- Print per-year ---\n",
    "    print(f\"{year} → Overlap: {len(overlap)} countries ({overlap_pct:.1f}%) → {sorted(overlap)}\")\n",
    "    \n",
    "    # --- Accumulate for sum-based total ---\n",
    "    total_overlap_sum  += len(overlap)\n",
    "    total_baseline_sum += len(score_countries)  # change to len(tertiary_countries) if you prefer that baseline\n",
    "    \n",
    "    # --- Accumulate for unique-country total ---\n",
    "    all_overlap_countries |= overlap\n",
    "    all_union_countries   |= (tertiary_countries | score_countries)\n",
    "\n",
    "# --- Sum-based total (e.g., '16 overlaps over 70 countries') ---\n",
    "if total_baseline_sum > 0:\n",
    "    total_pct_sum = total_overlap_sum / total_baseline_sum * 100\n",
    "else:\n",
    "    total_pct_sum = 0.0\n",
    "\n",
    "print(\"\\n=== TOTAL (sum-based) ===\")\n",
    "print(f\"Overlaps: {total_overlap_sum} over baseline {total_baseline_sum} → {total_pct_sum:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48624d-e2ab-4fb5-a912-6e46915e1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an indicator column so we can identify source\n",
    "top10_per_year_gdp[\"source\"] = \"GDP\"\n",
    "top10_total_score[\"source\"] = \"Total_Score\"\n",
    "\n",
    "# Merge both lists\n",
    "comparison_df = pd.concat([top10_per_year_gdp, top10_total_score], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e830a5ee-8311-44b7-b195-761be6c71867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your total_score data is in df_total_score with columns: country, year, total_score\n",
    "top10_total_score = (\n",
    "    total_score_df\n",
    "    .sort_values([\"year\", \"total_score\"], ascending=[True, False])\n",
    "    .groupby(\"year\")\n",
    "    .head(10)\n",
    "    .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a4e5e-b814-4a09-b8be-e5e2db748946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize totals\n",
    "total_overlap_sum = 0\n",
    "total_baseline_sum = 0\n",
    "\n",
    "# For the unique-country summary across the whole period:\n",
    "all_overlap_countries = set()\n",
    "all_union_countries = set()\n",
    "\n",
    "for year in sorted(comparison_df[\"year\"].unique()):\n",
    "    # --- Select countries for this year ---\n",
    "    gdp_countries   = set(top10_per_year_gdp[top10_per_year_gdp[\"year\"] == year][\"country\"])\n",
    "    score_countries = set(top10_total_score[top10_total_score[\"year\"] == year][\"country\"])\n",
    "    \n",
    "    # --- Calculate overlap ---\n",
    "    overlap = gdp_countries & score_countries\n",
    "    \n",
    "    # --- Yearly percentage (vs total_score list size) ---\n",
    "    overlap_pct = (len(overlap) / len(score_countries) * 100) if len(score_countries) else 0.0\n",
    "    \n",
    "    # --- Print per-year ---\n",
    "    print(f\"{year} → Overlap: {len(overlap)} countries ({overlap_pct:.1f}%) → {sorted(overlap)}\")\n",
    "    \n",
    "    # --- Accumulate for sum-based total ---\n",
    "    total_overlap_sum  += len(overlap)\n",
    "    total_baseline_sum += len(score_countries)      \n",
    "    \n",
    "    # --- Accumulate for unique-country total ---\n",
    "    all_overlap_countries |= overlap\n",
    "    all_union_countries   |= (gdp_countries | score_countries)\n",
    "\n",
    "# --- Sum-based total ---\n",
    "if total_baseline_sum > 0:\n",
    "    total_pct_sum = total_overlap_sum / total_baseline_sum * 100\n",
    "else:\n",
    "    total_pct_sum = 0.0\n",
    "\n",
    "print(\"\\n=== TOTAL (sum-based) ===\")\n",
    "print(f\"Overlaps: {total_overlap_sum} over baseline {total_baseline_sum} → {total_pct_sum:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675f1dc-d8f9-4ec9-8edb-a1ff95be3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize totals\n",
    "total_overlap_sum = 0\n",
    "total_baseline_sum = 0\n",
    "\n",
    "# For the unique-country summary across the whole period:\n",
    "all_overlap_countries = set()\n",
    "all_union_countries = set()\n",
    "\n",
    "for year in sorted(comparison_df[\"year\"].unique()):\n",
    "    # --- Select countries for this year ---\n",
    "    gov_countries   = set(top10_per_year_gov_eff[top10_per_year_gov_eff[\"year\"] == year][\"country\"])\n",
    "    score_countries = set(top10_total_score[top10_total_score[\"year\"] == year][\"country\"])\n",
    "    \n",
    "    # --- Calculate overlap ---\n",
    "    overlap = gov_countries & score_countries\n",
    "    \n",
    "    # --- Yearly percentage (vs total_score list size) ---\n",
    "    overlap_pct = (len(overlap) / len(score_countries) * 100) if len(score_countries) else 0.0\n",
    "    \n",
    "    # --- Print per-year ---\n",
    "    print(f\"{year} → Overlap: {len(overlap)} countries ({overlap_pct:.1f}%) → {sorted(overlap)}\")\n",
    "    \n",
    "    # --- Accumulate for sum-based total ---\n",
    "    total_overlap_sum  += len(overlap)\n",
    "    total_baseline_sum += len(score_countries)      \n",
    "    \n",
    "    # --- Accumulate for unique-country total ---\n",
    "    all_overlap_countries |= overlap\n",
    "    all_union_countries   |= (gov_countries | score_countries)\n",
    "\n",
    "# --- Sum-based total ---\n",
    "if total_baseline_sum > 0:\n",
    "    total_pct_sum = total_overlap_sum / total_baseline_sum * 100\n",
    "else:\n",
    "    total_pct_sum = 0.0\n",
    "\n",
    "print(\"\\n=== TOTAL (sum-based) ===\")\n",
    "print(f\"Overlaps: {total_overlap_sum} over baseline {total_baseline_sum} → {total_pct_sum:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec47fd4-c4da-4cfa-8ecc-6a58ba7d7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize totals\n",
    "total_overlap_sum = 0\n",
    "total_baseline_sum = 0\n",
    "\n",
    "# For the unique-country summary across the whole period:\n",
    "all_overlap_countries = set()\n",
    "all_union_countries = set()\n",
    "\n",
    "for year in sorted(comparison_df[\"year\"].unique()):\n",
    "    # --- Select countries for this year ---\n",
    "    res_countries   = set(top10_per_year_res[top10_per_year_res[\"year\"] == year][\"country\"])\n",
    "    score_countries = set(top10_total_score[top10_total_score[\"year\"] == year][\"country\"])\n",
    "    \n",
    "    # --- Calculate overlap ---\n",
    "    overlap = res_countries & score_countries\n",
    "    \n",
    "    # --- Yearly percentage (vs total_score list size) ---\n",
    "    overlap_pct = (len(overlap) / len(score_countries) * 100) if len(score_countries) else 0.0\n",
    "    \n",
    "    # --- Print per-year ---\n",
    "    print(f\"{year} → Overlap: {len(overlap)} countries ({overlap_pct:.1f}%) → {sorted(overlap)}\")\n",
    "    \n",
    "    # --- Accumulate for sum-based total ---\n",
    "    total_overlap_sum  += len(overlap)\n",
    "    total_baseline_sum += len(score_countries)      \n",
    "    \n",
    "    # --- Accumulate for unique-country total ---\n",
    "    all_overlap_countries |= overlap\n",
    "    all_union_countries   |= (res_countries | score_countries)\n",
    "\n",
    "# --- Sum-based total ---\n",
    "if total_baseline_sum > 0:\n",
    "    total_pct_sum = total_overlap_sum / total_baseline_sum * 100\n",
    "else:\n",
    "    total_pct_sum = 0.0\n",
    "\n",
    "print(\"\\n=== TOTAL (sum-based) ===\")\n",
    "print(f\"Overlaps: {total_overlap_sum} over baseline {total_baseline_sum} → {total_pct_sum:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88afe11f-baf3-43d1-80ba-063cc8264338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- 1) Standardize predictors ---\n",
    "X_vars = [\"gdp_per_capita\", \"gov_effectiveness\", \"gov_exp_edu\", \"rd_exp_gdp\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "analytic_std = analytic.copy()\n",
    "analytic_std[X_vars] = scaler.fit_transform(analytic_std[X_vars])\n",
    "\n",
    "# --- 2) Models ---\n",
    "\n",
    "# Model 1: No FE\n",
    "model_no_fe = smf.ols(\n",
    "    \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp\",\n",
    "    data=analytic_std\n",
    ").fit()\n",
    "\n",
    "# Model 2: Year FE only\n",
    "model_year_fe = smf.ols(\n",
    "    \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp + C(year)\",\n",
    "    data=analytic_std\n",
    ").fit()\n",
    "\n",
    "# Model 3: Country FE only\n",
    "model_country_fe = smf.ols(\n",
    "    \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp + C(country)\",\n",
    "    data=analytic_std\n",
    ").fit()\n",
    "\n",
    "# Model 4: Both Country & Year FE\n",
    "model_both_fe = smf.ols(\n",
    "    \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp + C(country) + C(year)\",\n",
    "    data=analytic_std\n",
    ").fit()\n",
    "\n",
    "# --- 3) R² comparison ---\n",
    "print(\"\\n=== Multiple Regression (OLS, standardized predictors) ===\")\n",
    "print(f\"No FE:           R² = {model_no_fe.rsquared:.3f}\")\n",
    "print(f\"Year FE only:    R² = {model_year_fe.rsquared:.3f}\")\n",
    "print(f\"Country FE only: R² = {model_country_fe.rsquared:.3f}\")\n",
    "print(f\"Both FE:         R² = {model_both_fe.rsquared:.3f}\")\n",
    "\n",
    "# --- 4) Coefficients (standardized, easier to compare) ---\n",
    "print(\"\\nStandardized Coefficients (No FE):\")\n",
    "print(model_no_fe.params[X_vars].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nStandardized Coefficients (Year FE):\")\n",
    "print(model_year_fe.params[X_vars].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nStandardized Coefficients (Country FE):\")\n",
    "print(model_country_fe.params[X_vars].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nStandardized Coefficients (Both FE):\")\n",
    "print(model_both_fe.params[X_vars].sort_values(ascending=False))\n",
    "\n",
    "# --- 5) Optionally save summaries ---\n",
    "with open(\"ols_no_fe_std.txt\", \"w\") as f: f.write(model_no_fe.summary().as_text())\n",
    "with open(\"ols_year_fe_std.txt\", \"w\") as f: f.write(model_year_fe.summary().as_text())\n",
    "with open(\"ols_country_fe_std.txt\", \"w\") as f: f.write(model_country_fe.summary().as_text())\n",
    "with open(\"ols_both_fe_std.txt\", \"w\") as f: f.write(model_both_fe.summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eed1d6-e68b-4691-b68a-fe47b29b7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 1: No Fixed Effects ---\n",
    "formula_no_fe = \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp\"\n",
    "ols_no_fe = smf.ols(formula=formula_no_fe, data=analytic).fit()\n",
    "\n",
    "# --- Model 2: Year Fixed Effects only ---\n",
    "formula_year_fe = \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp + C(year)\"\n",
    "ols_year_fe = smf.ols(formula=formula_year_fe, data=analytic).fit()\n",
    "\n",
    "# --- Model 3: Country Fixed Effects only ---\n",
    "formula_country_fe = \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp + C(country)\"\n",
    "ols_country_fe = smf.ols(formula=formula_country_fe, data=analytic).fit()\n",
    "\n",
    "# --- Model 4: Both Country & Year Fixed Effects ---\n",
    "formula_both_fe = \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp + C(country) + C(year)\"\n",
    "ols_both_fe = smf.ols(formula=formula_both_fe, data=analytic).fit()\n",
    "\n",
    "# --- Print R² comparison ---\n",
    "print(\"\\n=== Fixed Effects Comparison ===\")\n",
    "print(f\"No FE:           R² = {ols_no_fe.rsquared:.3f}\")\n",
    "print(f\"Year FE only:    R² = {ols_year_fe.rsquared:.3f}\")\n",
    "print(f\"Country FE only: R² = {ols_country_fe.rsquared:.3f}\")\n",
    "print(f\"Both FE:         R² = {ols_both_fe.rsquared:.3f}\")\n",
    "\n",
    "# --- Optional: check key coefficients for Year FE model ---\n",
    "print(\"\\nYear FE model coefficients:\")\n",
    "print(ols_year_fe.params[[\"gdp_per_capita\",\"gov_effectiveness\",\"gov_exp_edu\",\"rd_exp_gdp\"]])\n",
    "\n",
    "# --- Optional: save summaries to text files ---\n",
    "with open(\"ols_no_fe.txt\", \"w\") as f: f.write(ols_no_fe.summary().as_text())\n",
    "with open(\"ols_year_fe.txt\", \"w\") as f: f.write(ols_year_fe.summary().as_text())\n",
    "with open(\"ols_country_fe.txt\", \"w\") as f: f.write(ols_country_fe.summary().as_text())\n",
    "with open(\"ols_both_fe.txt\", \"w\") as f: f.write(ols_both_fe.summary().as_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d674ed-44e0-4a6a-b5e0-8c0cc3ee74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 1: No Fixed Effects ---\n",
    "formula_no_fe = \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp\"\n",
    "ols_no_fe = smf.ols(formula=formula_no_fe, data=analytic).fit()\n",
    "\n",
    "# --- Model 2: Year Fixed Effects only ---\n",
    "formula_year_fe = \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp + C(year)\"\n",
    "ols_year_fe = smf.ols(formula=formula_year_fe, data=analytic).fit()\n",
    "\n",
    "# --- Model 3: Country Fixed Effects only ---\n",
    "formula_country_fe = \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp + C(country)\"\n",
    "ols_country_fe = smf.ols(formula=formula_country_fe, data=analytic).fit()\n",
    "\n",
    "# --- Model 4: Both Country & Year Fixed Effects ---\n",
    "formula_both_fe = \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp + C(country) + C(year)\"\n",
    "ols_both_fe = smf.ols(formula=formula_both_fe, data=analytic).fit()\n",
    "\n",
    "# --- Print R² comparison ---\n",
    "print(\"\\n=== Fixed Effects Comparison ===\")\n",
    "print(f\"No FE:           R² = {ols_no_fe.rsquared:.3f}\")\n",
    "print(f\"Year FE only:    R² = {ols_year_fe.rsquared:.3f}\")\n",
    "print(f\"Country FE only: R² = {ols_country_fe.rsquared:.3f}\")\n",
    "print(f\"Both FE:         R² = {ols_both_fe.rsquared:.3f}\")\n",
    "\n",
    "# --- Optional: check key coefficients for Year FE model ---\n",
    "print(\"\\nYear FE model coefficients:\")\n",
    "print(ols_year_fe.params[[\"gdp_per_capita\",\"gov_effectiveness\",\"gov_exp_edu\",\"rd_exp_gdp\"]])\n",
    "\n",
    "# --- Optional: save summaries to text files ---\n",
    "with open(\"ols_no_fe.txt\", \"w\") as f: f.write(ols_no_fe.summary().as_text())\n",
    "with open(\"ols_year_fe.txt\", \"w\") as f: f.write(ols_year_fe.summary().as_text())\n",
    "with open(\"ols_country_fe.txt\", \"w\") as f: f.write(ols_country_fe.summary().as_text())\n",
    "with open(\"ols_both_fe.txt\", \"w\") as f: f.write(ols_both_fe.summary().as_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55e9a8-dbe4-41c0-9f0a-b95fa061d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 0) Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# === 1) Normalize column names & fix typos\n",
    "def normalize_cols(df):\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "          .str.strip()\n",
    "          .str.lower()\n",
    "          .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "    )\n",
    "    rename_map = {\n",
    "        \"ountry\": \"country\",\n",
    "        \"total score\": \"total_score\",\n",
    "        \"gdp_percapita\": \"gdp_per_capita\",\n",
    "        \"gov.effectivnes\": \"gov_effectiveness\",\n",
    "        \"gov.effectiveness\": \"gov_effectiveness\",\n",
    "        \"gov_exp_on_education\": \"gov_exp_edu\",\n",
    "        \"reseacrh_and_development\": \"rd_exp_gdp\",\n",
    "        \"research_and_development\": \"rd_exp_gdp\",\n",
    "        \"rd_exp_%gdp\": \"rd_exp_gdp\",\n",
    "        \"rd_exp_gdp(%)\": \"rd_exp_gdp\",\n",
    "    }\n",
    "    df = df.rename(columns=rename_map)\n",
    "    return df\n",
    "\n",
    "merged_df      = normalize_cols(merged_df)\n",
    "merged_df_edu  = normalize_cols(merged_df_edu)\n",
    "merged_df_gov  = normalize_cols(merged_df_gov)\n",
    "merged_rd      = normalize_cols(merged_rd)\n",
    "\n",
    "base = merged_df[[\"country\",\"year\",\"gdp_per_capita\",\"total_score\"]].copy()\n",
    "edu  = merged_df_edu[[\"country\",\"year\",\"gov_exp_edu\",\"total_score\"]].copy()\n",
    "gov  = merged_df_gov[[\"country\",\"year\",\"gov_effectiveness\",\"total_score\"]].copy()\n",
    "rd   = merged_rd[[\"country\",\"year\",\"rd_exp_gdp\",\"total_score\"]].copy()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# === 2) Deduplicate\n",
    "def dedupe(df, cols_keep):\n",
    "    return (\n",
    "        df.groupby([\"country\",\"year\"], as_index=False)\n",
    "          .agg({c:\"mean\" for c in cols_keep if c not in [\"country\",\"year\"]})\n",
    "    )\n",
    "\n",
    "base = dedupe(base, base.columns)\n",
    "edu  = dedupe(edu,  edu.columns)\n",
    "gov  = dedupe(gov,  gov.columns)\n",
    "rd   = dedupe(rd,   rd.columns)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# === 3) Merge into single analytic dataset\n",
    "analytic = (\n",
    "    base\n",
    "      .merge(edu[[\"country\",\"year\",\"gov_exp_edu\"]], on=[\"country\",\"year\"], how=\"left\")\n",
    "      .merge(gov[[\"country\",\"year\",\"gov_effectiveness\"]], on=[\"country\",\"year\"], how=\"left\")\n",
    "      .merge(rd[[\"country\",\"year\",\"rd_exp_gdp\"]], on=[\"country\",\"year\"], how=\"left\")\n",
    ")\n",
    "\n",
    "analytic = analytic.query(\"year >= 2017 and year <= 2022\")\n",
    "analytic = analytic.dropna(subset=[\"total_score\",\"gdp_per_capita\",\"gov_exp_edu\",\"gov_effectiveness\",\"rd_exp_gdp\"]).copy()\n",
    "\n",
    "print(\"Rows:\", len(analytic))\n",
    "print(analytic.head())\n",
    "\n",
    "analytic.to_csv(\"analytic_multivariate_dataset.csv\", index=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# === 4) VIF\n",
    "X_vars = [\"gdp_per_capita\",\"gov_effectiveness\",\"gov_exp_edu\",\"rd_exp_gdp\"]\n",
    "X_scaled = StandardScaler().fit_transform(analytic[X_vars])\n",
    "vif = pd.DataFrame({\n",
    "    \"feature\": X_vars,\n",
    "    \"VIF\": [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "})\n",
    "print(\"\\nVariance Inflation Factors (VIF):\\n\", vif.sort_values(\"VIF\", ascending=False))\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# === 5) OLS (no fixed effects)\n",
    "X = sm.add_constant(analytic[X_vars])\n",
    "y = analytic[\"total_score\"].values\n",
    "ols_plain = sm.OLS(y, X).fit()\n",
    "print(\"\\n=== OLS (no fixed effects) ===\")\n",
    "print(ols_plain.summary())\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# === 6) OLS with fixed effects\n",
    "formula_fe = \"total_score ~ gdp_per_capita + gov_effectiveness + gov_exp_edu + rd_exp_gdp + C(country) + C(year)\"\n",
    "ols_fe = smf.ols(formula=formula_fe, data=analytic).fit()\n",
    "print(\"\\n=== OLS with Country & Year Fixed Effects ===\")\n",
    "print(ols_fe.summary())\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# === 7) Standardized coefficients\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "Xs = scaler_X.fit_transform(analytic[X_vars])\n",
    "ys = scaler_y.fit_transform(analytic[[\"total_score\"]]).ravel()\n",
    "ols_std = sm.OLS(ys, sm.add_constant(Xs)).fit()\n",
    "beta_coefs = pd.Series(ols_std.params[1:], index=X_vars, name=\"std_beta\")\n",
    "print(\"\\nStandardized Betas (plain OLS):\\n\", beta_coefs.sort_values(ascending=False))\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# === 8) Ridge & Lasso\n",
    "alphas = np.logspace(-3, 3, 25)\n",
    "ridge = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "lasso = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LassoCV(alphas=alphas, cv=5, max_iter=10000))\n",
    "])\n",
    "X_mat = analytic[X_vars].values\n",
    "y_vec = analytic[\"total_score\"].values\n",
    "\n",
    "ridge.fit(X_mat, y_vec)\n",
    "lasso.fit(X_mat, y_vec)\n",
    "\n",
    "ridge_coefs = pd.Series(ridge.named_steps[\"model\"].coef_, index=X_vars, name=\"ridge_coef\")\n",
    "lasso_coefs = pd.Series(lasso.named_steps[\"model\"].coef_, index=X_vars, name=\"lasso_coef\")\n",
    "\n",
    "print(\"\\nRidge best alpha:\", ridge.named_steps[\"model\"].alpha_)\n",
    "print(\"Ridge coefficients:\\n\", ridge_coefs.sort_values(ascending=False))\n",
    "print(\"\\nLasso best alpha:\", lasso.named_steps[\"model\"].alpha_)\n",
    "print(\"Lasso coefficients:\\n\", lasso_coefs.sort_values(ascending=False))\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# === 9) Metrics with updated RMSE\n",
    "def metrics(y_true, y_pred, label):\n",
    "    print(f\"\\n[{label}] R2={r2_score(y_true,y_pred):.3f}  \"\n",
    "          f\"MAE={mean_absolute_error(y_true,y_pred):.2f}  \"\n",
    "          f\"RMSE={root_mean_squared_error(y_true,y_pred):.2f}\")\n",
    "\n",
    "metrics(y_vec, ols_plain.predict(X), \"OLS no-FE\")\n",
    "metrics(y_vec, ols_fe.fittedvalues, \"OLS with FE\")\n",
    "metrics(y_vec, ridge.predict(X_mat), \"Ridge\")\n",
    "metrics(y_vec, lasso.predict(X_mat), \"Lasso\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# === 10) Save OLS plain coefficient table\n",
    "coef_table = pd.DataFrame({\n",
    "    \"variable\": [\"const\"] + X_vars,\n",
    "    \"coef\": ols_plain.params,\n",
    "    \"std_err\": ols_plain.bse,\n",
    "    \"t\": ols_plain.tvalues,\n",
    "    \"pval\": ols_plain.pvalues\n",
    "})\n",
    "coef_table.to_csv(\"ols_plain_coef_table.csv\", index=False)\n",
    "print(\"\\nSaved: ols_plain_coef_table.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
